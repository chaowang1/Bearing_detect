{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From /home/coder_lzx_dev/Bearing_detect/autoencoder.py:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import autoencoder as ae\n",
    "#import classification as cf\n",
    "import autoencoder_depart as aed\n",
    "import depart_classification as dcf\n",
    "from input import Bearing_dataset\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "X = tf.placeholder(dtype = tf.float32, shape = [None, ae.num_input], name = 'layer_1_input')\n",
    "#layer_2_X = tf.placeholder(dtype = tf.float32, shape = [None, ae.num_hidden_1], name = 'layer_2_input')\n",
    "#layer_3_X = tf.placeholder(dtype = tf.float32, shape = [None, ae.num_hidden_2], name = 'layer_3_input')\n",
    "is_training = tf.placeholder(dtype = tf.bool, name = \"traing\")\n",
    "layer_1_para = aed.layer_para(X, aed.scope_name[0], is_training, 2.6e-3)\n",
    "layer_2_X = aed.Encoder(X, aed.scope_name[0], is_training)\n",
    "layer_2_para = aed.layer_para(layer_2_X, aed.scope_name[1], is_training, 8e-3)\n",
    "layer_3_X = aed.Encoder(layer_2_X, aed.scope_name[1], is_training)\n",
    "layer_3_para = aed.layer_para(layer_3_X, aed.scope_name[2], is_training, 6e-3)\n",
    "\n",
    "def run_autoencoder(session, loss_val, Xd, predict,\n",
    "                    drop_prob = 0.4,\n",
    "                    num_steps = 40, batch_size=256, print_every = 100,\n",
    "                    training = None, plot_losses = False):\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    train_indices = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indices)\n",
    "\n",
    "    variables = [loss_val, training, extra_update_ops]\n",
    "   \n",
    "    iter_cnt = 0\n",
    "    correct = 0\n",
    "    losses = []\n",
    "    for i in range(num_steps):\n",
    "        start_idx = (i * batch_size)%Xd.shape[0]\n",
    "        idx = train_indices[start_idx: start_idx + batch_size]\n",
    "\n",
    "        feed_dict = {X: Xd[idx, :], is_training: training is not None}\n",
    "        actual_batch_size = Xd[idx].shape[0]\n",
    "        loss,  _, _ = session.run(variables, feed_dict = feed_dict)\n",
    "        losses.append(loss * actual_batch_size)\n",
    "        #correct += np.sum(corr)\n",
    "\n",
    "        if (iter_cnt%print_every) == 0:\n",
    "            print(\"Iteration{0}: with minibatch training loss = {1:.3g}\".format(iter_cnt, loss))\n",
    "        iter_cnt += 1\n",
    "    total_loss = np.sum(losses)/Xd.shape[0]\n",
    "    print(\"Overall loss = {0:.3g} \".format(total_loss))\n",
    "    if plot_losses:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel(\"minibatch number\")\n",
    "        plt.ylabel('minibatch loss')\n",
    "        plt.show()\n",
    "    return total_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ae.mnist.train.images\n",
    "train_labels = np.asarray(ae.mnist.train.labels, dtype=np.int32)\n",
    "eval_data = ae.mnist.test.images\n",
    "eval_labels = np.asarray(ae.mnist.test.labels, dtype=np.int32)\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "b_train_data = Bearing_dataset.train_data\n",
    "b_train_labels = Bearing_dataset.train_label\n",
    "b_train_labels = tf.one_hot(b_train_labels, 10)\n",
    "b_eval_labels = Bearing_dataset.eval_label\n",
    "b_eval_labels = tf.one_hot(b_eval_labels, 10)\n",
    "b_eval_data = Bearing_dataset.eval_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot:0\", shape=(800, 10), dtype=float32)\n",
      "(800, 1200)\n"
     ]
    }
   ],
   "source": [
    "print(b_train_labels)\n",
    "print(b_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain layer_1:\n",
      "Iteration0: with minibatch training loss = 1.29\n",
      "Iteration50: with minibatch training loss = 0.678\n",
      "Iteration100: with minibatch training loss = 0.562\n",
      "Iteration150: with minibatch training loss = 0.52\n",
      "Iteration200: with minibatch training loss = 0.493\n",
      "Iteration250: with minibatch training loss = 0.475\n",
      "Iteration300: with minibatch training loss = 0.461\n",
      "Iteration350: with minibatch training loss = 0.451\n",
      "Iteration400: with minibatch training loss = 0.442\n",
      "Iteration450: with minibatch training loss = 0.436\n",
      "Iteration500: with minibatch training loss = 0.429\n",
      "Iteration550: with minibatch training loss = 0.424\n",
      "Iteration600: with minibatch training loss = 0.42\n",
      "Iteration650: with minibatch training loss = 0.416\n",
      "Iteration700: with minibatch training loss = 0.413\n",
      "Iteration750: with minibatch training loss = 0.41\n",
      "Iteration800: with minibatch training loss = 0.407\n",
      "Iteration850: with minibatch training loss = 0.404\n",
      "Iteration900: with minibatch training loss = 0.402\n",
      "Iteration950: with minibatch training loss = 0.4\n",
      "Overall loss = 255 \n",
      "Pretrain layer_2:\n",
      "Iteration0: with minibatch training loss = 1.02\n",
      "Iteration50: with minibatch training loss = 0.976\n",
      "Iteration100: with minibatch training loss = 0.592\n",
      "Iteration150: with minibatch training loss = 0.201\n",
      "Iteration200: with minibatch training loss = 0.0796\n",
      "Iteration250: with minibatch training loss = 0.058\n",
      "Iteration300: with minibatch training loss = 0.104\n",
      "Overall loss = 52.5 \n",
      "Pretrain layer_3:\n",
      "Iteration0: with minibatch training loss = 0.929\n",
      "Iteration50: with minibatch training loss = 0.68\n",
      "Iteration100: with minibatch training loss = 0.398\n",
      "Iteration150: with minibatch training loss = 0.129\n",
      "Iteration200: with minibatch training loss = 0.037\n",
      "Overall loss = 36.6 \n",
      "train\n",
      "Iteration0: with minibatch training loss = 3.2 and accuracy of 0.096\n",
      "Epoch 1, Overall loss = 3.01 and accuracy of 0.107\n",
      "Epoch 2, Overall loss = 2.4 and accuracy of 0.185\n",
      "Epoch 3, Overall loss = 2.23 and accuracy of 0.21\n",
      "Epoch 4, Overall loss = 2.2 and accuracy of 0.199\n",
      "Epoch 5, Overall loss = 2.11 and accuracy of 0.233\n",
      "Epoch 6, Overall loss = 2.05 and accuracy of 0.24\n",
      "Epoch 7, Overall loss = 1.98 and accuracy of 0.265\n",
      "Epoch 8, Overall loss = 1.91 and accuracy of 0.276\n",
      "Epoch 9, Overall loss = 1.83 and accuracy of 0.311\n",
      "Epoch 10, Overall loss = 1.8 and accuracy of 0.31\n",
      "Epoch 11, Overall loss = 1.79 and accuracy of 0.287\n",
      "Epoch 12, Overall loss = 1.74 and accuracy of 0.324\n",
      "Epoch 13, Overall loss = 1.73 and accuracy of 0.32\n",
      "Epoch 14, Overall loss = 1.7 and accuracy of 0.306\n",
      "Epoch 15, Overall loss = 1.68 and accuracy of 0.328\n",
      "Epoch 16, Overall loss = 1.65 and accuracy of 0.345\n",
      "Epoch 17, Overall loss = 1.62 and accuracy of 0.371\n",
      "Epoch 18, Overall loss = 1.61 and accuracy of 0.349\n",
      "Epoch 19, Overall loss = 1.6 and accuracy of 0.365\n",
      "Epoch 20, Overall loss = 1.56 and accuracy of 0.372\n",
      "Epoch 21, Overall loss = 1.54 and accuracy of 0.376\n",
      "Epoch 22, Overall loss = 1.53 and accuracy of 0.411\n",
      "Epoch 23, Overall loss = 1.52 and accuracy of 0.4\n",
      "Epoch 24, Overall loss = 1.51 and accuracy of 0.395\n",
      "Epoch 25, Overall loss = 1.5 and accuracy of 0.401\n",
      "Epoch 26, Overall loss = 1.49 and accuracy of 0.426\n",
      "Epoch 27, Overall loss = 1.45 and accuracy of 0.436\n",
      "Epoch 28, Overall loss = 1.43 and accuracy of 0.427\n",
      "Epoch 29, Overall loss = 1.39 and accuracy of 0.464\n",
      "Epoch 30, Overall loss = 1.36 and accuracy of 0.466\n",
      "Epoch 31, Overall loss = 1.37 and accuracy of 0.453\n",
      "Epoch 32, Overall loss = 1.32 and accuracy of 0.486\n",
      "Epoch 33, Overall loss = 1.32 and accuracy of 0.484\n",
      "Epoch 34, Overall loss = 1.29 and accuracy of 0.479\n",
      "Epoch 35, Overall loss = 1.31 and accuracy of 0.476\n",
      "Epoch 36, Overall loss = 1.24 and accuracy of 0.502\n",
      "Epoch 37, Overall loss = 1.26 and accuracy of 0.506\n",
      "Epoch 38, Overall loss = 1.26 and accuracy of 0.506\n",
      "Epoch 39, Overall loss = 1.2 and accuracy of 0.545\n",
      "Epoch 40, Overall loss = 1.19 and accuracy of 0.551\n",
      "Epoch 41, Overall loss = 1.17 and accuracy of 0.561\n",
      "Epoch 42, Overall loss = 1.17 and accuracy of 0.557\n",
      "Epoch 43, Overall loss = 1.14 and accuracy of 0.542\n",
      "Epoch 44, Overall loss = 1.13 and accuracy of 0.559\n",
      "Epoch 45, Overall loss = 1.1 and accuracy of 0.58\n",
      "Epoch 46, Overall loss = 1.08 and accuracy of 0.594\n",
      "Epoch 47, Overall loss = 1.03 and accuracy of 0.619\n",
      "Epoch 48, Overall loss = 1.04 and accuracy of 0.615\n",
      "Epoch 49, Overall loss = 0.965 and accuracy of 0.642\n",
      "Epoch 50, Overall loss = 0.975 and accuracy of 0.632\n",
      "Iteration100: with minibatch training loss = 0.929 and accuracy of 0.66\n",
      "Epoch 51, Overall loss = 0.939 and accuracy of 0.645\n",
      "Epoch 52, Overall loss = 0.974 and accuracy of 0.632\n",
      "Epoch 53, Overall loss = 0.901 and accuracy of 0.651\n",
      "Epoch 54, Overall loss = 0.902 and accuracy of 0.655\n",
      "Epoch 55, Overall loss = 0.868 and accuracy of 0.677\n",
      "Epoch 56, Overall loss = 0.847 and accuracy of 0.709\n",
      "Epoch 57, Overall loss = 0.839 and accuracy of 0.691\n",
      "Epoch 58, Overall loss = 0.804 and accuracy of 0.703\n",
      "Epoch 59, Overall loss = 0.782 and accuracy of 0.726\n",
      "Epoch 60, Overall loss = 0.784 and accuracy of 0.723\n",
      "Epoch 61, Overall loss = 0.773 and accuracy of 0.738\n",
      "Epoch 62, Overall loss = 0.729 and accuracy of 0.74\n",
      "Epoch 63, Overall loss = 0.72 and accuracy of 0.746\n",
      "Epoch 64, Overall loss = 0.732 and accuracy of 0.738\n",
      "Epoch 65, Overall loss = 0.728 and accuracy of 0.73\n",
      "Epoch 66, Overall loss = 0.663 and accuracy of 0.757\n",
      "Epoch 67, Overall loss = 0.672 and accuracy of 0.78\n",
      "Epoch 68, Overall loss = 0.658 and accuracy of 0.765\n",
      "Epoch 69, Overall loss = 0.632 and accuracy of 0.797\n",
      "Epoch 70, Overall loss = 0.625 and accuracy of 0.797\n",
      "Epoch 71, Overall loss = 0.641 and accuracy of 0.781\n",
      "Epoch 72, Overall loss = 0.612 and accuracy of 0.792\n",
      "Epoch 73, Overall loss = 0.577 and accuracy of 0.811\n",
      "Epoch 74, Overall loss = 0.571 and accuracy of 0.81\n",
      "Epoch 75, Overall loss = 0.558 and accuracy of 0.824\n",
      "Epoch 76, Overall loss = 0.561 and accuracy of 0.8\n",
      "Epoch 77, Overall loss = 0.567 and accuracy of 0.819\n",
      "Epoch 78, Overall loss = 0.558 and accuracy of 0.828\n",
      "Epoch 79, Overall loss = 0.533 and accuracy of 0.836\n",
      "Epoch 80, Overall loss = 0.587 and accuracy of 0.816\n",
      "Epoch 81, Overall loss = 0.541 and accuracy of 0.829\n",
      "Epoch 82, Overall loss = 0.548 and accuracy of 0.821\n",
      "Epoch 83, Overall loss = 0.512 and accuracy of 0.841\n",
      "Epoch 84, Overall loss = 0.493 and accuracy of 0.849\n",
      "Epoch 85, Overall loss = 0.533 and accuracy of 0.851\n",
      "Epoch 86, Overall loss = 0.496 and accuracy of 0.838\n",
      "Epoch 87, Overall loss = 0.549 and accuracy of 0.82\n",
      "Epoch 88, Overall loss = 0.479 and accuracy of 0.86\n",
      "Epoch 89, Overall loss = 0.46 and accuracy of 0.864\n",
      "Epoch 90, Overall loss = 0.485 and accuracy of 0.853\n",
      "Epoch 91, Overall loss = 0.465 and accuracy of 0.855\n",
      "Epoch 92, Overall loss = 0.453 and accuracy of 0.863\n",
      "Epoch 93, Overall loss = 0.434 and accuracy of 0.873\n",
      "Epoch 94, Overall loss = 0.474 and accuracy of 0.865\n",
      "Epoch 95, Overall loss = 0.438 and accuracy of 0.87\n",
      "Epoch 96, Overall loss = 0.398 and accuracy of 0.88\n",
      "Epoch 97, Overall loss = 0.407 and accuracy of 0.881\n",
      "Epoch 98, Overall loss = 0.422 and accuracy of 0.88\n",
      "Epoch 99, Overall loss = 0.406 and accuracy of 0.886\n",
      "Epoch 100, Overall loss = 0.442 and accuracy of 0.869\n",
      "Iteration200: with minibatch training loss = 0.438 and accuracy of 0.87\n",
      "Epoch 101, Overall loss = 0.408 and accuracy of 0.877\n",
      "Epoch 102, Overall loss = 0.443 and accuracy of 0.863\n",
      "Epoch 103, Overall loss = 0.386 and accuracy of 0.894\n",
      "Epoch 104, Overall loss = 0.405 and accuracy of 0.881\n",
      "Epoch 105, Overall loss = 0.407 and accuracy of 0.885\n",
      "Epoch 106, Overall loss = 0.376 and accuracy of 0.902\n",
      "Epoch 107, Overall loss = 0.358 and accuracy of 0.894\n",
      "Epoch 108, Overall loss = 0.382 and accuracy of 0.887\n",
      "Epoch 109, Overall loss = 0.381 and accuracy of 0.892\n",
      "Epoch 110, Overall loss = 0.352 and accuracy of 0.911\n",
      "Epoch 111, Overall loss = 0.352 and accuracy of 0.909\n",
      "Epoch 112, Overall loss = 0.371 and accuracy of 0.897\n",
      "Epoch 113, Overall loss = 0.351 and accuracy of 0.911\n",
      "Epoch 114, Overall loss = 0.332 and accuracy of 0.907\n",
      "Epoch 115, Overall loss = 0.345 and accuracy of 0.906\n",
      "Epoch 116, Overall loss = 0.331 and accuracy of 0.931\n",
      "Epoch 117, Overall loss = 0.338 and accuracy of 0.902\n",
      "Epoch 118, Overall loss = 0.303 and accuracy of 0.931\n",
      "Epoch 119, Overall loss = 0.355 and accuracy of 0.909\n",
      "Epoch 120, Overall loss = 0.331 and accuracy of 0.921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121, Overall loss = 0.285 and accuracy of 0.935\n",
      "Epoch 122, Overall loss = 0.282 and accuracy of 0.938\n",
      "Epoch 123, Overall loss = 0.292 and accuracy of 0.934\n",
      "Epoch 124, Overall loss = 0.279 and accuracy of 0.949\n",
      "Epoch 125, Overall loss = 0.275 and accuracy of 0.938\n",
      "Epoch 126, Overall loss = 0.303 and accuracy of 0.932\n",
      "Epoch 127, Overall loss = 0.263 and accuracy of 0.941\n",
      "Epoch 128, Overall loss = 0.262 and accuracy of 0.939\n",
      "Epoch 129, Overall loss = 0.267 and accuracy of 0.949\n",
      "Epoch 130, Overall loss = 0.273 and accuracy of 0.948\n",
      "Epoch 131, Overall loss = 0.283 and accuracy of 0.935\n",
      "Epoch 132, Overall loss = 0.255 and accuracy of 0.958\n",
      "Epoch 133, Overall loss = 0.26 and accuracy of 0.941\n",
      "Epoch 134, Overall loss = 0.244 and accuracy of 0.958\n",
      "Epoch 135, Overall loss = 0.257 and accuracy of 0.945\n",
      "Epoch 136, Overall loss = 0.281 and accuracy of 0.931\n",
      "Epoch 137, Overall loss = 0.255 and accuracy of 0.935\n",
      "Epoch 138, Overall loss = 0.268 and accuracy of 0.939\n",
      "Epoch 139, Overall loss = 0.272 and accuracy of 0.944\n",
      "Epoch 140, Overall loss = 0.248 and accuracy of 0.948\n",
      "Epoch 141, Overall loss = 0.235 and accuracy of 0.946\n",
      "Epoch 142, Overall loss = 0.246 and accuracy of 0.943\n",
      "Epoch 143, Overall loss = 0.239 and accuracy of 0.96\n",
      "Epoch 144, Overall loss = 0.234 and accuracy of 0.956\n",
      "Epoch 145, Overall loss = 0.244 and accuracy of 0.946\n",
      "Epoch 146, Overall loss = 0.237 and accuracy of 0.959\n",
      "Epoch 147, Overall loss = 0.252 and accuracy of 0.951\n",
      "Epoch 148, Overall loss = 0.259 and accuracy of 0.939\n",
      "Epoch 149, Overall loss = 0.217 and accuracy of 0.964\n",
      "Epoch 150, Overall loss = 0.21 and accuracy of 0.966\n",
      "Iteration300: with minibatch training loss = 0.223 and accuracy of 0.96\n",
      "Epoch 151, Overall loss = 0.208 and accuracy of 0.971\n",
      "Epoch 152, Overall loss = 0.232 and accuracy of 0.953\n",
      "Epoch 153, Overall loss = 0.231 and accuracy of 0.95\n",
      "Epoch 154, Overall loss = 0.22 and accuracy of 0.959\n",
      "Epoch 155, Overall loss = 0.241 and accuracy of 0.95\n",
      "Epoch 156, Overall loss = 0.194 and accuracy of 0.975\n",
      "Epoch 157, Overall loss = 0.209 and accuracy of 0.955\n",
      "Epoch 158, Overall loss = 0.249 and accuracy of 0.94\n",
      "Epoch 159, Overall loss = 0.191 and accuracy of 0.968\n",
      "Epoch 160, Overall loss = 0.214 and accuracy of 0.959\n",
      "Epoch 161, Overall loss = 0.204 and accuracy of 0.97\n",
      "Epoch 162, Overall loss = 0.204 and accuracy of 0.96\n",
      "Epoch 163, Overall loss = 0.204 and accuracy of 0.963\n",
      "Epoch 164, Overall loss = 0.196 and accuracy of 0.965\n",
      "Epoch 165, Overall loss = 0.179 and accuracy of 0.971\n",
      "Epoch 166, Overall loss = 0.198 and accuracy of 0.97\n",
      "Epoch 167, Overall loss = 0.185 and accuracy of 0.975\n",
      "Epoch 168, Overall loss = 0.174 and accuracy of 0.975\n",
      "Epoch 169, Overall loss = 0.191 and accuracy of 0.965\n",
      "Epoch 170, Overall loss = 0.2 and accuracy of 0.971\n",
      "Epoch 171, Overall loss = 0.225 and accuracy of 0.954\n",
      "Epoch 172, Overall loss = 0.17 and accuracy of 0.979\n",
      "Epoch 173, Overall loss = 0.175 and accuracy of 0.971\n",
      "Epoch 174, Overall loss = 0.176 and accuracy of 0.97\n",
      "Epoch 175, Overall loss = 0.192 and accuracy of 0.965\n",
      "Epoch 176, Overall loss = 0.174 and accuracy of 0.974\n",
      "Epoch 177, Overall loss = 0.175 and accuracy of 0.973\n",
      "Epoch 178, Overall loss = 0.171 and accuracy of 0.971\n",
      "Epoch 179, Overall loss = 0.155 and accuracy of 0.978\n",
      "Epoch 180, Overall loss = 0.159 and accuracy of 0.975\n",
      "Epoch 181, Overall loss = 0.177 and accuracy of 0.974\n",
      "Epoch 182, Overall loss = 0.172 and accuracy of 0.973\n",
      "Epoch 183, Overall loss = 0.178 and accuracy of 0.974\n",
      "Epoch 184, Overall loss = 0.206 and accuracy of 0.965\n",
      "Epoch 185, Overall loss = 0.148 and accuracy of 0.98\n",
      "Epoch 186, Overall loss = 0.159 and accuracy of 0.98\n",
      "Epoch 187, Overall loss = 0.153 and accuracy of 0.978\n",
      "Epoch 188, Overall loss = 0.171 and accuracy of 0.97\n",
      "Epoch 189, Overall loss = 0.174 and accuracy of 0.968\n",
      "Epoch 190, Overall loss = 0.171 and accuracy of 0.975\n",
      "Epoch 191, Overall loss = 0.165 and accuracy of 0.974\n",
      "Epoch 192, Overall loss = 0.144 and accuracy of 0.981\n",
      "Epoch 193, Overall loss = 0.165 and accuracy of 0.971\n",
      "Epoch 194, Overall loss = 0.14 and accuracy of 0.983\n",
      "Epoch 195, Overall loss = 0.155 and accuracy of 0.978\n",
      "Epoch 196, Overall loss = 0.165 and accuracy of 0.969\n",
      "Epoch 197, Overall loss = 0.137 and accuracy of 0.985\n",
      "Epoch 198, Overall loss = 0.161 and accuracy of 0.981\n",
      "Epoch 199, Overall loss = 0.173 and accuracy of 0.966\n",
      "Epoch 200, Overall loss = 0.131 and accuracy of 0.98\n",
      "Iteration400: with minibatch training loss = 0.17 and accuracy of 0.98\n",
      "Epoch 201, Overall loss = 0.147 and accuracy of 0.986\n",
      "Epoch 202, Overall loss = 0.142 and accuracy of 0.976\n",
      "Epoch 203, Overall loss = 0.15 and accuracy of 0.979\n",
      "Epoch 204, Overall loss = 0.149 and accuracy of 0.979\n",
      "Epoch 205, Overall loss = 0.13 and accuracy of 0.984\n",
      "Epoch 206, Overall loss = 0.134 and accuracy of 0.986\n",
      "Epoch 207, Overall loss = 0.147 and accuracy of 0.979\n",
      "Epoch 208, Overall loss = 0.132 and accuracy of 0.988\n",
      "Epoch 209, Overall loss = 0.131 and accuracy of 0.985\n",
      "Epoch 210, Overall loss = 0.134 and accuracy of 0.981\n",
      "Epoch 211, Overall loss = 0.152 and accuracy of 0.98\n",
      "Epoch 212, Overall loss = 0.122 and accuracy of 0.983\n",
      "Epoch 213, Overall loss = 0.125 and accuracy of 0.981\n",
      "Epoch 214, Overall loss = 0.171 and accuracy of 0.973\n",
      "Epoch 215, Overall loss = 0.144 and accuracy of 0.984\n",
      "Epoch 216, Overall loss = 0.142 and accuracy of 0.983\n",
      "Epoch 217, Overall loss = 0.124 and accuracy of 0.988\n",
      "Epoch 218, Overall loss = 0.157 and accuracy of 0.974\n",
      "Epoch 219, Overall loss = 0.12 and accuracy of 0.984\n",
      "Epoch 220, Overall loss = 0.133 and accuracy of 0.985\n",
      "Epoch 221, Overall loss = 0.149 and accuracy of 0.974\n",
      "Epoch 222, Overall loss = 0.129 and accuracy of 0.984\n",
      "Epoch 223, Overall loss = 0.122 and accuracy of 0.984\n",
      "Epoch 224, Overall loss = 0.131 and accuracy of 0.98\n",
      "Epoch 225, Overall loss = 0.129 and accuracy of 0.985\n",
      "Epoch 226, Overall loss = 0.136 and accuracy of 0.984\n",
      "Epoch 227, Overall loss = 0.13 and accuracy of 0.986\n",
      "Epoch 228, Overall loss = 0.117 and accuracy of 0.988\n",
      "Epoch 229, Overall loss = 0.136 and accuracy of 0.974\n",
      "Epoch 230, Overall loss = 0.112 and accuracy of 0.988\n",
      "Epoch 231, Overall loss = 0.119 and accuracy of 0.985\n",
      "Epoch 232, Overall loss = 0.12 and accuracy of 0.988\n",
      "Epoch 233, Overall loss = 0.117 and accuracy of 0.984\n",
      "Epoch 234, Overall loss = 0.12 and accuracy of 0.988\n",
      "Epoch 235, Overall loss = 0.13 and accuracy of 0.979\n",
      "Epoch 236, Overall loss = 0.112 and accuracy of 0.988\n",
      "Epoch 237, Overall loss = 0.11 and accuracy of 0.986\n",
      "Epoch 238, Overall loss = 0.125 and accuracy of 0.98\n",
      "Epoch 239, Overall loss = 0.108 and accuracy of 0.988\n",
      "Epoch 240, Overall loss = 0.109 and accuracy of 0.986\n",
      "Epoch 241, Overall loss = 0.124 and accuracy of 0.983\n",
      "Epoch 242, Overall loss = 0.133 and accuracy of 0.978\n",
      "Epoch 243, Overall loss = 0.13 and accuracy of 0.983\n",
      "Epoch 244, Overall loss = 0.126 and accuracy of 0.983\n",
      "Epoch 245, Overall loss = 0.121 and accuracy of 0.985\n",
      "Epoch 246, Overall loss = 0.108 and accuracy of 0.993\n",
      "Epoch 247, Overall loss = 0.112 and accuracy of 0.985\n",
      "Epoch 248, Overall loss = 0.131 and accuracy of 0.98\n",
      "Epoch 249, Overall loss = 0.104 and accuracy of 0.99\n",
      "Epoch 250, Overall loss = 0.109 and accuracy of 0.988\n",
      "Iteration500: with minibatch training loss = 0.159 and accuracy of 0.97\n",
      "Epoch 251, Overall loss = 0.142 and accuracy of 0.978\n",
      "Epoch 252, Overall loss = 0.111 and accuracy of 0.984\n",
      "Epoch 253, Overall loss = 0.104 and accuracy of 0.988\n",
      "Epoch 254, Overall loss = 0.142 and accuracy of 0.981\n",
      "Epoch 255, Overall loss = 0.134 and accuracy of 0.983\n",
      "Epoch 256, Overall loss = 0.136 and accuracy of 0.975\n",
      "Epoch 257, Overall loss = 0.117 and accuracy of 0.986\n",
      "Epoch 258, Overall loss = 0.113 and accuracy of 0.988\n",
      "Epoch 259, Overall loss = 0.109 and accuracy of 0.986\n",
      "Epoch 260, Overall loss = 0.0996 and accuracy of 0.989\n",
      "Epoch 261, Overall loss = 0.107 and accuracy of 0.988\n",
      "Epoch 262, Overall loss = 0.111 and accuracy of 0.984\n",
      "Epoch 263, Overall loss = 0.104 and accuracy of 0.99\n",
      "Epoch 264, Overall loss = 0.0973 and accuracy of 0.991\n",
      "Epoch 265, Overall loss = 0.101 and accuracy of 0.986\n",
      "Epoch 266, Overall loss = 0.107 and accuracy of 0.985\n",
      "Epoch 267, Overall loss = 0.11 and accuracy of 0.988\n",
      "Epoch 268, Overall loss = 0.0938 and accuracy of 0.99\n",
      "Epoch 269, Overall loss = 0.0975 and accuracy of 0.988\n",
      "Epoch 270, Overall loss = 0.0934 and accuracy of 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271, Overall loss = 0.0873 and accuracy of 0.991\n",
      "Epoch 272, Overall loss = 0.113 and accuracy of 0.984\n",
      "Epoch 273, Overall loss = 0.113 and accuracy of 0.986\n",
      "Epoch 274, Overall loss = 0.114 and accuracy of 0.989\n",
      "Epoch 275, Overall loss = 0.0934 and accuracy of 0.995\n",
      "Epoch 276, Overall loss = 0.0934 and accuracy of 0.994\n",
      "Epoch 277, Overall loss = 0.108 and accuracy of 0.985\n",
      "Epoch 278, Overall loss = 0.083 and accuracy of 0.996\n",
      "Epoch 279, Overall loss = 0.103 and accuracy of 0.988\n",
      "Epoch 280, Overall loss = 0.118 and accuracy of 0.98\n",
      "Epoch 281, Overall loss = 0.0897 and accuracy of 0.993\n",
      "Epoch 282, Overall loss = 0.0904 and accuracy of 0.991\n",
      "Epoch 283, Overall loss = 0.115 and accuracy of 0.988\n",
      "Epoch 284, Overall loss = 0.086 and accuracy of 0.996\n",
      "Epoch 285, Overall loss = 0.0984 and accuracy of 0.989\n",
      "Epoch 286, Overall loss = 0.101 and accuracy of 0.99\n",
      "Epoch 287, Overall loss = 0.0852 and accuracy of 0.993\n",
      "Epoch 288, Overall loss = 0.0918 and accuracy of 0.989\n",
      "Epoch 289, Overall loss = 0.111 and accuracy of 0.988\n",
      "Epoch 290, Overall loss = 0.0825 and accuracy of 0.995\n",
      "Epoch 291, Overall loss = 0.093 and accuracy of 0.991\n",
      "Epoch 292, Overall loss = 0.0828 and accuracy of 0.993\n",
      "Epoch 293, Overall loss = 0.089 and accuracy of 0.993\n",
      "Epoch 294, Overall loss = 0.102 and accuracy of 0.989\n",
      "Epoch 295, Overall loss = 0.102 and accuracy of 0.985\n",
      "Epoch 296, Overall loss = 0.0984 and accuracy of 0.986\n",
      "Epoch 297, Overall loss = 0.0983 and accuracy of 0.989\n",
      "Epoch 298, Overall loss = 0.0932 and accuracy of 0.988\n",
      "Epoch 299, Overall loss = 0.0816 and accuracy of 0.994\n",
      "Epoch 300, Overall loss = 0.0902 and accuracy of 0.989\n",
      "Iteration600: with minibatch training loss = 0.0833 and accuracy of 1\n",
      "Epoch 301, Overall loss = 0.0854 and accuracy of 0.995\n",
      "Epoch 302, Overall loss = 0.0906 and accuracy of 0.989\n",
      "Epoch 303, Overall loss = 0.0767 and accuracy of 0.995\n",
      "Epoch 304, Overall loss = 0.0813 and accuracy of 0.993\n",
      "Epoch 305, Overall loss = 0.0943 and accuracy of 0.988\n",
      "Epoch 306, Overall loss = 0.0906 and accuracy of 0.99\n",
      "Epoch 307, Overall loss = 0.0922 and accuracy of 0.993\n",
      "Epoch 308, Overall loss = 0.107 and accuracy of 0.988\n",
      "Epoch 309, Overall loss = 0.0849 and accuracy of 0.991\n",
      "Epoch 310, Overall loss = 0.085 and accuracy of 0.988\n",
      "Epoch 311, Overall loss = 0.102 and accuracy of 0.985\n",
      "Epoch 312, Overall loss = 0.104 and accuracy of 0.989\n",
      "Epoch 313, Overall loss = 0.105 and accuracy of 0.988\n",
      "Epoch 314, Overall loss = 0.113 and accuracy of 0.984\n",
      "Epoch 315, Overall loss = 0.0962 and accuracy of 0.99\n",
      "Epoch 316, Overall loss = 0.0932 and accuracy of 0.991\n",
      "Epoch 317, Overall loss = 0.0827 and accuracy of 0.991\n",
      "Epoch 318, Overall loss = 0.0905 and accuracy of 0.986\n",
      "Epoch 319, Overall loss = 0.101 and accuracy of 0.988\n",
      "Epoch 320, Overall loss = 0.0804 and accuracy of 0.989\n",
      "Epoch 321, Overall loss = 0.0971 and accuracy of 0.988\n",
      "Epoch 322, Overall loss = 0.0991 and accuracy of 0.991\n",
      "Epoch 323, Overall loss = 0.0864 and accuracy of 0.988\n",
      "Epoch 324, Overall loss = 0.088 and accuracy of 0.99\n",
      "Epoch 325, Overall loss = 0.111 and accuracy of 0.983\n",
      "Epoch 326, Overall loss = 0.0855 and accuracy of 0.994\n",
      "Epoch 327, Overall loss = 0.09 and accuracy of 0.989\n",
      "Epoch 328, Overall loss = 0.088 and accuracy of 0.99\n",
      "Epoch 329, Overall loss = 0.0877 and accuracy of 0.988\n",
      "Epoch 330, Overall loss = 0.079 and accuracy of 0.995\n",
      "Epoch 331, Overall loss = 0.0871 and accuracy of 0.99\n",
      "Epoch 332, Overall loss = 0.0871 and accuracy of 0.993\n",
      "Epoch 333, Overall loss = 0.0889 and accuracy of 0.99\n",
      "Epoch 334, Overall loss = 0.0992 and accuracy of 0.99\n",
      "Epoch 335, Overall loss = 0.09 and accuracy of 0.993\n",
      "Epoch 336, Overall loss = 0.101 and accuracy of 0.988\n",
      "Epoch 337, Overall loss = 0.0881 and accuracy of 0.988\n",
      "Epoch 338, Overall loss = 0.0968 and accuracy of 0.99\n",
      "Epoch 339, Overall loss = 0.0899 and accuracy of 0.986\n",
      "Epoch 340, Overall loss = 0.103 and accuracy of 0.989\n",
      "Epoch 341, Overall loss = 0.0868 and accuracy of 0.99\n",
      "Epoch 342, Overall loss = 0.101 and accuracy of 0.988\n",
      "Epoch 343, Overall loss = 0.0926 and accuracy of 0.991\n",
      "Epoch 344, Overall loss = 0.0853 and accuracy of 0.989\n",
      "Epoch 345, Overall loss = 0.0883 and accuracy of 0.991\n",
      "Epoch 346, Overall loss = 0.1 and accuracy of 0.985\n",
      "Epoch 347, Overall loss = 0.0868 and accuracy of 0.986\n",
      "Epoch 348, Overall loss = 0.0915 and accuracy of 0.991\n",
      "Epoch 349, Overall loss = 0.0875 and accuracy of 0.99\n",
      "Epoch 350, Overall loss = 0.0769 and accuracy of 0.994\n",
      "Iteration700: with minibatch training loss = 0.0926 and accuracy of 0.98\n",
      "Epoch 351, Overall loss = 0.0873 and accuracy of 0.986\n",
      "Epoch 352, Overall loss = 0.0792 and accuracy of 0.993\n",
      "Epoch 353, Overall loss = 0.0791 and accuracy of 0.993\n",
      "Epoch 354, Overall loss = 0.0825 and accuracy of 0.991\n",
      "Epoch 355, Overall loss = 0.0755 and accuracy of 0.998\n",
      "Epoch 356, Overall loss = 0.0808 and accuracy of 0.994\n",
      "Epoch 357, Overall loss = 0.0938 and accuracy of 0.993\n",
      "Epoch 358, Overall loss = 0.0773 and accuracy of 0.991\n",
      "Epoch 359, Overall loss = 0.0835 and accuracy of 0.991\n",
      "Epoch 360, Overall loss = 0.0786 and accuracy of 0.991\n",
      "Epoch 361, Overall loss = 0.082 and accuracy of 0.989\n",
      "Epoch 362, Overall loss = 0.0785 and accuracy of 0.99\n",
      "Epoch 363, Overall loss = 0.0791 and accuracy of 0.993\n",
      "Epoch 364, Overall loss = 0.0954 and accuracy of 0.99\n",
      "Epoch 365, Overall loss = 0.0876 and accuracy of 0.985\n",
      "Epoch 366, Overall loss = 0.0724 and accuracy of 0.995\n",
      "Epoch 367, Overall loss = 0.0724 and accuracy of 0.995\n",
      "Epoch 368, Overall loss = 0.0829 and accuracy of 0.993\n",
      "Epoch 369, Overall loss = 0.0732 and accuracy of 0.991\n",
      "Epoch 370, Overall loss = 0.103 and accuracy of 0.988\n",
      "Epoch 371, Overall loss = 0.0727 and accuracy of 0.991\n",
      "Epoch 372, Overall loss = 0.107 and accuracy of 0.983\n",
      "Epoch 373, Overall loss = 0.0876 and accuracy of 0.993\n",
      "Epoch 374, Overall loss = 0.0972 and accuracy of 0.983\n",
      "Epoch 375, Overall loss = 0.075 and accuracy of 0.993\n",
      "Epoch 376, Overall loss = 0.0802 and accuracy of 0.986\n",
      "Epoch 377, Overall loss = 0.0698 and accuracy of 0.995\n",
      "Epoch 378, Overall loss = 0.0901 and accuracy of 0.988\n",
      "Epoch 379, Overall loss = 0.0751 and accuracy of 0.99\n",
      "Epoch 380, Overall loss = 0.0807 and accuracy of 0.991\n",
      "Epoch 381, Overall loss = 0.0685 and accuracy of 0.998\n",
      "Epoch 382, Overall loss = 0.0693 and accuracy of 0.995\n",
      "Epoch 383, Overall loss = 0.0982 and accuracy of 0.986\n",
      "Epoch 384, Overall loss = 0.0884 and accuracy of 0.989\n",
      "Epoch 385, Overall loss = 0.0646 and accuracy of 0.995\n",
      "Epoch 386, Overall loss = 0.0735 and accuracy of 0.994\n",
      "Epoch 387, Overall loss = 0.0772 and accuracy of 0.995\n",
      "Epoch 388, Overall loss = 0.0801 and accuracy of 0.991\n",
      "Epoch 389, Overall loss = 0.0885 and accuracy of 0.994\n",
      "Epoch 390, Overall loss = 0.0797 and accuracy of 0.989\n",
      "Epoch 391, Overall loss = 0.077 and accuracy of 0.986\n",
      "Epoch 392, Overall loss = 0.0753 and accuracy of 0.991\n",
      "Epoch 393, Overall loss = 0.0833 and accuracy of 0.995\n",
      "Epoch 394, Overall loss = 0.0782 and accuracy of 0.993\n",
      "Epoch 395, Overall loss = 0.0675 and accuracy of 0.994\n",
      "Epoch 396, Overall loss = 0.0847 and accuracy of 0.984\n",
      "Epoch 397, Overall loss = 0.0813 and accuracy of 0.988\n",
      "Epoch 398, Overall loss = 0.0898 and accuracy of 0.985\n",
      "Epoch 399, Overall loss = 0.0713 and accuracy of 0.996\n",
      "Epoch 400, Overall loss = 0.0737 and accuracy of 0.993\n",
      "Iteration800: with minibatch training loss = 0.0736 and accuracy of 0.99\n",
      "Epoch 401, Overall loss = 0.0745 and accuracy of 0.989\n",
      "Epoch 402, Overall loss = 0.0659 and accuracy of 0.993\n",
      "Epoch 403, Overall loss = 0.0862 and accuracy of 0.988\n",
      "Epoch 404, Overall loss = 0.079 and accuracy of 0.993\n",
      "Epoch 405, Overall loss = 0.0935 and accuracy of 0.986\n",
      "Epoch 406, Overall loss = 0.0824 and accuracy of 0.993\n",
      "Epoch 407, Overall loss = 0.0838 and accuracy of 0.99\n",
      "Epoch 408, Overall loss = 0.0827 and accuracy of 0.989\n",
      "Epoch 409, Overall loss = 0.0812 and accuracy of 0.988\n",
      "Epoch 410, Overall loss = 0.0733 and accuracy of 0.99\n",
      "Epoch 411, Overall loss = 0.0618 and accuracy of 0.996\n",
      "Epoch 412, Overall loss = 0.0712 and accuracy of 0.993\n",
      "Epoch 413, Overall loss = 0.0883 and accuracy of 0.988\n",
      "Epoch 414, Overall loss = 0.082 and accuracy of 0.989\n",
      "Epoch 415, Overall loss = 0.0843 and accuracy of 0.991\n",
      "Epoch 416, Overall loss = 0.0843 and accuracy of 0.991\n",
      "Epoch 417, Overall loss = 0.077 and accuracy of 0.993\n",
      "Epoch 418, Overall loss = 0.0682 and accuracy of 0.991\n",
      "Epoch 419, Overall loss = 0.0776 and accuracy of 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420, Overall loss = 0.0711 and accuracy of 0.991\n",
      "Epoch 421, Overall loss = 0.0943 and accuracy of 0.986\n",
      "Epoch 422, Overall loss = 0.0706 and accuracy of 0.995\n",
      "Epoch 423, Overall loss = 0.0851 and accuracy of 0.993\n",
      "Epoch 424, Overall loss = 0.0642 and accuracy of 0.99\n",
      "Epoch 425, Overall loss = 0.075 and accuracy of 0.99\n",
      "Epoch 426, Overall loss = 0.0673 and accuracy of 0.993\n",
      "Epoch 427, Overall loss = 0.0858 and accuracy of 0.99\n",
      "Epoch 428, Overall loss = 0.0767 and accuracy of 0.991\n",
      "Epoch 429, Overall loss = 0.0883 and accuracy of 0.989\n",
      "Epoch 430, Overall loss = 0.085 and accuracy of 0.989\n",
      "Epoch 431, Overall loss = 0.0788 and accuracy of 0.989\n",
      "Epoch 432, Overall loss = 0.0736 and accuracy of 0.994\n",
      "Epoch 433, Overall loss = 0.0928 and accuracy of 0.985\n",
      "Epoch 434, Overall loss = 0.074 and accuracy of 0.991\n",
      "Epoch 435, Overall loss = 0.0832 and accuracy of 0.993\n",
      "Epoch 436, Overall loss = 0.0672 and accuracy of 0.993\n",
      "Epoch 437, Overall loss = 0.0875 and accuracy of 0.988\n",
      "Epoch 438, Overall loss = 0.0712 and accuracy of 0.994\n",
      "Epoch 439, Overall loss = 0.088 and accuracy of 0.985\n",
      "Epoch 440, Overall loss = 0.082 and accuracy of 0.988\n",
      "Epoch 441, Overall loss = 0.0705 and accuracy of 0.99\n",
      "Epoch 442, Overall loss = 0.08 and accuracy of 0.989\n",
      "Epoch 443, Overall loss = 0.0945 and accuracy of 0.989\n",
      "Epoch 444, Overall loss = 0.0853 and accuracy of 0.988\n",
      "Epoch 445, Overall loss = 0.0711 and accuracy of 0.989\n",
      "Epoch 446, Overall loss = 0.0728 and accuracy of 0.994\n",
      "Epoch 447, Overall loss = 0.0905 and accuracy of 0.983\n",
      "Epoch 448, Overall loss = 0.0908 and accuracy of 0.986\n",
      "Epoch 449, Overall loss = 0.0729 and accuracy of 0.989\n",
      "Epoch 450, Overall loss = 0.0744 and accuracy of 0.991\n",
      "Iteration900: with minibatch training loss = 0.0698 and accuracy of 0.99\n",
      "Epoch 451, Overall loss = 0.0699 and accuracy of 0.99\n",
      "Epoch 452, Overall loss = 0.0831 and accuracy of 0.991\n",
      "Epoch 453, Overall loss = 0.0859 and accuracy of 0.986\n",
      "Epoch 454, Overall loss = 0.0822 and accuracy of 0.988\n",
      "Epoch 455, Overall loss = 0.0957 and accuracy of 0.985\n",
      "Epoch 456, Overall loss = 0.0796 and accuracy of 0.991\n",
      "Epoch 457, Overall loss = 0.0852 and accuracy of 0.986\n",
      "Epoch 458, Overall loss = 0.0718 and accuracy of 0.993\n",
      "Epoch 459, Overall loss = 0.105 and accuracy of 0.983\n",
      "Epoch 460, Overall loss = 0.0923 and accuracy of 0.983\n",
      "Epoch 461, Overall loss = 0.0808 and accuracy of 0.99\n",
      "Epoch 462, Overall loss = 0.0814 and accuracy of 0.989\n",
      "Epoch 463, Overall loss = 0.0711 and accuracy of 0.991\n",
      "Epoch 464, Overall loss = 0.0851 and accuracy of 0.986\n",
      "Epoch 465, Overall loss = 0.067 and accuracy of 0.994\n",
      "Epoch 466, Overall loss = 0.0903 and accuracy of 0.989\n",
      "Epoch 467, Overall loss = 0.0648 and accuracy of 0.991\n",
      "Epoch 468, Overall loss = 0.0899 and accuracy of 0.99\n",
      "Epoch 469, Overall loss = 0.0609 and accuracy of 0.991\n",
      "Epoch 470, Overall loss = 0.0682 and accuracy of 0.993\n",
      "Epoch 471, Overall loss = 0.0722 and accuracy of 0.989\n",
      "Epoch 472, Overall loss = 0.0777 and accuracy of 0.993\n",
      "Epoch 473, Overall loss = 0.0663 and accuracy of 0.994\n",
      "Epoch 474, Overall loss = 0.0733 and accuracy of 0.991\n",
      "Epoch 475, Overall loss = 0.0616 and accuracy of 0.993\n",
      "Epoch 476, Overall loss = 0.0945 and accuracy of 0.985\n",
      "Epoch 477, Overall loss = 0.0767 and accuracy of 0.988\n",
      "Epoch 478, Overall loss = 0.0651 and accuracy of 0.996\n",
      "Epoch 479, Overall loss = 0.0969 and accuracy of 0.984\n",
      "Epoch 480, Overall loss = 0.082 and accuracy of 0.991\n",
      "Epoch 481, Overall loss = 0.0675 and accuracy of 0.989\n",
      "Epoch 482, Overall loss = 0.0782 and accuracy of 0.991\n",
      "Epoch 483, Overall loss = 0.0709 and accuracy of 0.994\n",
      "Epoch 484, Overall loss = 0.0693 and accuracy of 0.993\n",
      "Epoch 485, Overall loss = 0.0577 and accuracy of 0.994\n",
      "Epoch 486, Overall loss = 0.088 and accuracy of 0.986\n",
      "Epoch 487, Overall loss = 0.0844 and accuracy of 0.985\n",
      "Epoch 488, Overall loss = 0.0772 and accuracy of 0.988\n",
      "Epoch 489, Overall loss = 0.0887 and accuracy of 0.99\n",
      "Epoch 490, Overall loss = 0.0874 and accuracy of 0.983\n",
      "Epoch 491, Overall loss = 0.0719 and accuracy of 0.993\n",
      "Epoch 492, Overall loss = 0.0734 and accuracy of 0.99\n",
      "Epoch 493, Overall loss = 0.0722 and accuracy of 0.985\n",
      "Epoch 494, Overall loss = 0.0971 and accuracy of 0.986\n",
      "Epoch 495, Overall loss = 0.0887 and accuracy of 0.988\n",
      "Epoch 496, Overall loss = 0.0744 and accuracy of 0.988\n",
      "Epoch 497, Overall loss = 0.0809 and accuracy of 0.984\n",
      "Epoch 498, Overall loss = 0.0866 and accuracy of 0.989\n",
      "Epoch 499, Overall loss = 0.0825 and accuracy of 0.989\n",
      "Epoch 500, Overall loss = 0.0773 and accuracy of 0.989\n",
      "Iteration1000: with minibatch training loss = 0.0665 and accuracy of 1\n",
      "Epoch 501, Overall loss = 0.0632 and accuracy of 0.996\n",
      "Epoch 502, Overall loss = 0.0673 and accuracy of 0.99\n",
      "Epoch 503, Overall loss = 0.0837 and accuracy of 0.989\n",
      "Epoch 504, Overall loss = 0.075 and accuracy of 0.991\n",
      "Epoch 505, Overall loss = 0.0854 and accuracy of 0.988\n",
      "Epoch 506, Overall loss = 0.0993 and accuracy of 0.984\n",
      "Epoch 507, Overall loss = 0.0994 and accuracy of 0.984\n",
      "Epoch 508, Overall loss = 0.0692 and accuracy of 0.991\n",
      "Epoch 509, Overall loss = 0.0777 and accuracy of 0.991\n",
      "Epoch 510, Overall loss = 0.1 and accuracy of 0.983\n",
      "Epoch 511, Overall loss = 0.0759 and accuracy of 0.986\n",
      "Epoch 512, Overall loss = 0.0674 and accuracy of 0.991\n",
      "Epoch 513, Overall loss = 0.0896 and accuracy of 0.986\n",
      "Epoch 514, Overall loss = 0.0972 and accuracy of 0.981\n",
      "Epoch 515, Overall loss = 0.067 and accuracy of 0.994\n",
      "Epoch 516, Overall loss = 0.073 and accuracy of 0.994\n",
      "Epoch 517, Overall loss = 0.0831 and accuracy of 0.989\n",
      "Epoch 518, Overall loss = 0.0918 and accuracy of 0.986\n",
      "Epoch 519, Overall loss = 0.0569 and accuracy of 0.996\n",
      "Epoch 520, Overall loss = 0.0777 and accuracy of 0.989\n",
      "Epoch 521, Overall loss = 0.0659 and accuracy of 0.99\n",
      "Epoch 522, Overall loss = 0.0764 and accuracy of 0.988\n",
      "Epoch 523, Overall loss = 0.067 and accuracy of 0.995\n",
      "Epoch 524, Overall loss = 0.0639 and accuracy of 0.994\n",
      "Epoch 525, Overall loss = 0.0773 and accuracy of 0.988\n",
      "Epoch 526, Overall loss = 0.0665 and accuracy of 0.993\n",
      "Epoch 527, Overall loss = 0.0962 and accuracy of 0.981\n",
      "Epoch 528, Overall loss = 0.0793 and accuracy of 0.986\n",
      "Epoch 529, Overall loss = 0.0677 and accuracy of 0.994\n",
      "Epoch 530, Overall loss = 0.0612 and accuracy of 0.996\n",
      "Epoch 531, Overall loss = 0.1 and accuracy of 0.985\n",
      "Epoch 532, Overall loss = 0.0614 and accuracy of 0.995\n",
      "Epoch 533, Overall loss = 0.0754 and accuracy of 0.989\n",
      "Epoch 534, Overall loss = 0.0714 and accuracy of 0.995\n",
      "Epoch 535, Overall loss = 0.0957 and accuracy of 0.988\n",
      "Epoch 536, Overall loss = 0.0713 and accuracy of 0.994\n",
      "Epoch 537, Overall loss = 0.0716 and accuracy of 0.99\n",
      "Epoch 538, Overall loss = 0.0945 and accuracy of 0.985\n",
      "Epoch 539, Overall loss = 0.0745 and accuracy of 0.993\n",
      "Epoch 540, Overall loss = 0.0574 and accuracy of 0.996\n",
      "Epoch 541, Overall loss = 0.0727 and accuracy of 0.99\n",
      "Epoch 542, Overall loss = 0.0614 and accuracy of 0.995\n",
      "Epoch 543, Overall loss = 0.0646 and accuracy of 0.991\n",
      "Epoch 544, Overall loss = 0.102 and accuracy of 0.988\n",
      "Epoch 545, Overall loss = 0.0727 and accuracy of 0.993\n",
      "Epoch 546, Overall loss = 0.065 and accuracy of 0.991\n",
      "Epoch 547, Overall loss = 0.0847 and accuracy of 0.986\n",
      "Epoch 548, Overall loss = 0.0928 and accuracy of 0.986\n",
      "Epoch 549, Overall loss = 0.0811 and accuracy of 0.984\n",
      "Epoch 550, Overall loss = 0.0558 and accuracy of 0.995\n",
      "Iteration1100: with minibatch training loss = 0.101 and accuracy of 0.98\n",
      "Epoch 551, Overall loss = 0.0847 and accuracy of 0.983\n",
      "Epoch 552, Overall loss = 0.0864 and accuracy of 0.993\n",
      "Epoch 553, Overall loss = 0.0727 and accuracy of 0.989\n",
      "Epoch 554, Overall loss = 0.104 and accuracy of 0.981\n",
      "Epoch 555, Overall loss = 0.0761 and accuracy of 0.988\n",
      "Epoch 556, Overall loss = 0.0837 and accuracy of 0.988\n",
      "Epoch 557, Overall loss = 0.0641 and accuracy of 0.995\n",
      "Epoch 558, Overall loss = 0.0674 and accuracy of 0.991\n",
      "Epoch 559, Overall loss = 0.0848 and accuracy of 0.989\n",
      "Epoch 560, Overall loss = 0.0808 and accuracy of 0.985\n",
      "Epoch 561, Overall loss = 0.075 and accuracy of 0.986\n",
      "Epoch 562, Overall loss = 0.0624 and accuracy of 0.993\n",
      "Epoch 563, Overall loss = 0.0666 and accuracy of 0.991\n",
      "Epoch 564, Overall loss = 0.0755 and accuracy of 0.99\n",
      "Epoch 565, Overall loss = 0.0643 and accuracy of 0.991\n",
      "Epoch 566, Overall loss = 0.0813 and accuracy of 0.988\n",
      "Epoch 567, Overall loss = 0.0803 and accuracy of 0.991\n",
      "Epoch 568, Overall loss = 0.0744 and accuracy of 0.993\n",
      "Epoch 569, Overall loss = 0.0748 and accuracy of 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570, Overall loss = 0.0647 and accuracy of 0.991\n",
      "Epoch 571, Overall loss = 0.0644 and accuracy of 0.993\n",
      "Epoch 572, Overall loss = 0.0758 and accuracy of 0.988\n",
      "Epoch 573, Overall loss = 0.0799 and accuracy of 0.985\n",
      "Epoch 574, Overall loss = 0.0762 and accuracy of 0.984\n",
      "Epoch 575, Overall loss = 0.101 and accuracy of 0.983\n",
      "Epoch 576, Overall loss = 0.0797 and accuracy of 0.986\n",
      "Epoch 577, Overall loss = 0.0645 and accuracy of 0.993\n",
      "Epoch 578, Overall loss = 0.0833 and accuracy of 0.988\n",
      "Epoch 579, Overall loss = 0.068 and accuracy of 0.993\n",
      "Epoch 580, Overall loss = 0.0604 and accuracy of 0.993\n",
      "Epoch 581, Overall loss = 0.084 and accuracy of 0.985\n",
      "Epoch 582, Overall loss = 0.0627 and accuracy of 0.991\n",
      "Epoch 583, Overall loss = 0.0687 and accuracy of 0.991\n",
      "Epoch 584, Overall loss = 0.0722 and accuracy of 0.99\n",
      "Epoch 585, Overall loss = 0.0815 and accuracy of 0.985\n",
      "Epoch 586, Overall loss = 0.0893 and accuracy of 0.985\n",
      "Epoch 587, Overall loss = 0.0603 and accuracy of 0.994\n",
      "Epoch 588, Overall loss = 0.0717 and accuracy of 0.993\n",
      "Epoch 589, Overall loss = 0.0855 and accuracy of 0.984\n",
      "Epoch 590, Overall loss = 0.0634 and accuracy of 0.995\n",
      "Epoch 591, Overall loss = 0.0765 and accuracy of 0.988\n",
      "Epoch 592, Overall loss = 0.0669 and accuracy of 0.993\n",
      "Epoch 593, Overall loss = 0.0574 and accuracy of 0.996\n",
      "Epoch 594, Overall loss = 0.0837 and accuracy of 0.991\n",
      "Epoch 595, Overall loss = 0.0763 and accuracy of 0.984\n",
      "Epoch 596, Overall loss = 0.0824 and accuracy of 0.989\n",
      "Epoch 597, Overall loss = 0.0814 and accuracy of 0.989\n",
      "Epoch 598, Overall loss = 0.0648 and accuracy of 0.99\n",
      "Epoch 599, Overall loss = 0.0691 and accuracy of 0.988\n",
      "Epoch 600, Overall loss = 0.0583 and accuracy of 0.991\n",
      "Iteration1200: with minibatch training loss = 0.0768 and accuracy of 0.99\n",
      "Epoch 601, Overall loss = 0.0708 and accuracy of 0.989\n",
      "Epoch 602, Overall loss = 0.0682 and accuracy of 0.991\n",
      "Epoch 603, Overall loss = 0.0743 and accuracy of 0.988\n",
      "Epoch 604, Overall loss = 0.0647 and accuracy of 0.991\n",
      "Epoch 605, Overall loss = 0.0604 and accuracy of 0.994\n",
      "Epoch 606, Overall loss = 0.0491 and accuracy of 0.996\n",
      "Epoch 607, Overall loss = 0.0665 and accuracy of 0.99\n",
      "Epoch 608, Overall loss = 0.0608 and accuracy of 0.994\n",
      "Epoch 609, Overall loss = 0.0684 and accuracy of 0.99\n",
      "Epoch 610, Overall loss = 0.0586 and accuracy of 0.995\n",
      "Epoch 611, Overall loss = 0.0759 and accuracy of 0.991\n",
      "Epoch 612, Overall loss = 0.0618 and accuracy of 0.994\n",
      "Epoch 613, Overall loss = 0.0712 and accuracy of 0.99\n",
      "Epoch 614, Overall loss = 0.0767 and accuracy of 0.988\n",
      "Epoch 615, Overall loss = 0.0534 and accuracy of 0.993\n",
      "Epoch 616, Overall loss = 0.0789 and accuracy of 0.99\n",
      "Epoch 617, Overall loss = 0.0696 and accuracy of 0.99\n",
      "Epoch 618, Overall loss = 0.0787 and accuracy of 0.986\n",
      "Epoch 619, Overall loss = 0.0773 and accuracy of 0.986\n",
      "Epoch 620, Overall loss = 0.07 and accuracy of 0.991\n",
      "Epoch 621, Overall loss = 0.0548 and accuracy of 0.994\n",
      "Epoch 622, Overall loss = 0.0577 and accuracy of 0.995\n",
      "Epoch 623, Overall loss = 0.0539 and accuracy of 0.996\n",
      "Epoch 624, Overall loss = 0.065 and accuracy of 0.993\n",
      "Epoch 625, Overall loss = 0.0668 and accuracy of 0.988\n",
      "Epoch 626, Overall loss = 0.0673 and accuracy of 0.994\n",
      "Epoch 627, Overall loss = 0.0676 and accuracy of 0.988\n",
      "Epoch 628, Overall loss = 0.0628 and accuracy of 0.995\n",
      "Epoch 629, Overall loss = 0.0512 and accuracy of 0.994\n",
      "Epoch 630, Overall loss = 0.0698 and accuracy of 0.99\n",
      "Epoch 631, Overall loss = 0.0745 and accuracy of 0.989\n",
      "Epoch 632, Overall loss = 0.0526 and accuracy of 0.995\n",
      "Epoch 633, Overall loss = 0.0543 and accuracy of 0.991\n",
      "Epoch 634, Overall loss = 0.0627 and accuracy of 0.993\n",
      "Epoch 635, Overall loss = 0.0696 and accuracy of 0.99\n",
      "Epoch 636, Overall loss = 0.0584 and accuracy of 0.994\n",
      "Epoch 637, Overall loss = 0.0666 and accuracy of 0.994\n",
      "Epoch 638, Overall loss = 0.086 and accuracy of 0.985\n",
      "Epoch 639, Overall loss = 0.0534 and accuracy of 0.993\n",
      "Epoch 640, Overall loss = 0.0569 and accuracy of 0.995\n",
      "Epoch 641, Overall loss = 0.053 and accuracy of 0.996\n",
      "Epoch 642, Overall loss = 0.0767 and accuracy of 0.988\n",
      "Epoch 643, Overall loss = 0.0766 and accuracy of 0.986\n",
      "Epoch 644, Overall loss = 0.0603 and accuracy of 0.989\n",
      "Epoch 645, Overall loss = 0.0712 and accuracy of 0.988\n",
      "Epoch 646, Overall loss = 0.0608 and accuracy of 0.993\n",
      "Epoch 647, Overall loss = 0.0646 and accuracy of 0.991\n",
      "Epoch 648, Overall loss = 0.0586 and accuracy of 0.995\n",
      "Epoch 649, Overall loss = 0.0725 and accuracy of 0.99\n",
      "Epoch 650, Overall loss = 0.0589 and accuracy of 0.995\n",
      "Iteration1300: with minibatch training loss = 0.0746 and accuracy of 0.99\n",
      "Epoch 651, Overall loss = 0.0763 and accuracy of 0.988\n",
      "Epoch 652, Overall loss = 0.0739 and accuracy of 0.989\n",
      "Epoch 653, Overall loss = 0.0642 and accuracy of 0.99\n",
      "Epoch 654, Overall loss = 0.0671 and accuracy of 0.99\n",
      "Epoch 655, Overall loss = 0.0521 and accuracy of 0.996\n",
      "Epoch 656, Overall loss = 0.0446 and accuracy of 0.999\n",
      "Epoch 657, Overall loss = 0.0746 and accuracy of 0.988\n",
      "Epoch 658, Overall loss = 0.0545 and accuracy of 0.995\n",
      "Epoch 659, Overall loss = 0.0513 and accuracy of 0.998\n",
      "Epoch 660, Overall loss = 0.0467 and accuracy of 0.998\n",
      "Epoch 661, Overall loss = 0.0575 and accuracy of 0.995\n",
      "Epoch 662, Overall loss = 0.0613 and accuracy of 0.993\n",
      "Epoch 663, Overall loss = 0.0662 and accuracy of 0.99\n",
      "Epoch 664, Overall loss = 0.0685 and accuracy of 0.989\n",
      "Epoch 665, Overall loss = 0.0713 and accuracy of 0.989\n",
      "Epoch 666, Overall loss = 0.072 and accuracy of 0.986\n",
      "Epoch 667, Overall loss = 0.063 and accuracy of 0.991\n",
      "Epoch 668, Overall loss = 0.0728 and accuracy of 0.993\n",
      "Epoch 669, Overall loss = 0.0667 and accuracy of 0.99\n",
      "Epoch 670, Overall loss = 0.0562 and accuracy of 0.991\n",
      "Epoch 671, Overall loss = 0.0587 and accuracy of 0.994\n",
      "Epoch 672, Overall loss = 0.0732 and accuracy of 0.989\n",
      "Epoch 673, Overall loss = 0.0547 and accuracy of 0.991\n",
      "Epoch 674, Overall loss = 0.0614 and accuracy of 0.995\n",
      "Epoch 675, Overall loss = 0.0511 and accuracy of 0.995\n",
      "Epoch 676, Overall loss = 0.0634 and accuracy of 0.99\n",
      "Epoch 677, Overall loss = 0.0804 and accuracy of 0.989\n",
      "Epoch 678, Overall loss = 0.0601 and accuracy of 0.993\n",
      "Epoch 679, Overall loss = 0.0498 and accuracy of 0.996\n",
      "Epoch 680, Overall loss = 0.0734 and accuracy of 0.985\n",
      "Epoch 681, Overall loss = 0.0495 and accuracy of 0.996\n",
      "Epoch 682, Overall loss = 0.0538 and accuracy of 0.996\n",
      "Epoch 683, Overall loss = 0.0834 and accuracy of 0.986\n",
      "Epoch 684, Overall loss = 0.0725 and accuracy of 0.989\n",
      "Epoch 685, Overall loss = 0.0608 and accuracy of 0.993\n",
      "Epoch 686, Overall loss = 0.0673 and accuracy of 0.988\n",
      "Epoch 687, Overall loss = 0.048 and accuracy of 0.998\n",
      "Epoch 688, Overall loss = 0.0728 and accuracy of 0.993\n",
      "Epoch 689, Overall loss = 0.0737 and accuracy of 0.993\n",
      "Epoch 690, Overall loss = 0.0775 and accuracy of 0.991\n",
      "Epoch 691, Overall loss = 0.0478 and accuracy of 0.995\n",
      "Epoch 692, Overall loss = 0.0621 and accuracy of 0.991\n",
      "Epoch 693, Overall loss = 0.0593 and accuracy of 0.99\n",
      "Epoch 694, Overall loss = 0.0462 and accuracy of 0.996\n",
      "Epoch 695, Overall loss = 0.0548 and accuracy of 0.994\n",
      "Epoch 696, Overall loss = 0.0583 and accuracy of 0.994\n",
      "Epoch 697, Overall loss = 0.0487 and accuracy of 0.998\n",
      "Epoch 698, Overall loss = 0.0595 and accuracy of 0.994\n",
      "Epoch 699, Overall loss = 0.0518 and accuracy of 0.999\n",
      "Epoch 700, Overall loss = 0.0545 and accuracy of 0.994\n",
      "Iteration1400: with minibatch training loss = 0.0525 and accuracy of 0.99\n",
      "Epoch 701, Overall loss = 0.064 and accuracy of 0.988\n",
      "Epoch 702, Overall loss = 0.0935 and accuracy of 0.983\n",
      "Epoch 703, Overall loss = 0.0628 and accuracy of 0.993\n",
      "Epoch 704, Overall loss = 0.0627 and accuracy of 0.995\n",
      "Epoch 705, Overall loss = 0.064 and accuracy of 0.993\n",
      "Epoch 706, Overall loss = 0.0594 and accuracy of 0.993\n",
      "Epoch 707, Overall loss = 0.0589 and accuracy of 0.991\n",
      "Epoch 708, Overall loss = 0.0682 and accuracy of 0.993\n",
      "Epoch 709, Overall loss = 0.0631 and accuracy of 0.989\n",
      "Epoch 710, Overall loss = 0.0631 and accuracy of 0.99\n",
      "Epoch 711, Overall loss = 0.0544 and accuracy of 0.994\n",
      "Epoch 712, Overall loss = 0.0535 and accuracy of 0.994\n",
      "Epoch 713, Overall loss = 0.0631 and accuracy of 0.989\n",
      "Epoch 714, Overall loss = 0.0669 and accuracy of 0.988\n",
      "Epoch 715, Overall loss = 0.0699 and accuracy of 0.994\n",
      "Epoch 716, Overall loss = 0.0454 and accuracy of 0.995\n",
      "Epoch 717, Overall loss = 0.0576 and accuracy of 0.993\n",
      "Epoch 718, Overall loss = 0.0599 and accuracy of 0.991\n",
      "Epoch 719, Overall loss = 0.0607 and accuracy of 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720, Overall loss = 0.0565 and accuracy of 0.991\n",
      "Epoch 721, Overall loss = 0.0532 and accuracy of 0.993\n",
      "Epoch 722, Overall loss = 0.0525 and accuracy of 0.995\n",
      "Epoch 723, Overall loss = 0.0604 and accuracy of 0.994\n",
      "Epoch 724, Overall loss = 0.0675 and accuracy of 0.99\n",
      "Epoch 725, Overall loss = 0.0579 and accuracy of 0.993\n",
      "Epoch 726, Overall loss = 0.0581 and accuracy of 0.99\n",
      "Epoch 727, Overall loss = 0.0464 and accuracy of 0.998\n",
      "Epoch 728, Overall loss = 0.0491 and accuracy of 0.995\n",
      "Epoch 729, Overall loss = 0.0656 and accuracy of 0.988\n",
      "Epoch 730, Overall loss = 0.0481 and accuracy of 0.995\n",
      "Epoch 731, Overall loss = 0.0624 and accuracy of 0.993\n",
      "Epoch 732, Overall loss = 0.061 and accuracy of 0.989\n",
      "Epoch 733, Overall loss = 0.0705 and accuracy of 0.986\n",
      "Epoch 734, Overall loss = 0.0556 and accuracy of 0.994\n",
      "Epoch 735, Overall loss = 0.0516 and accuracy of 0.995\n",
      "Epoch 736, Overall loss = 0.0607 and accuracy of 0.993\n",
      "Epoch 737, Overall loss = 0.0554 and accuracy of 0.993\n",
      "Epoch 738, Overall loss = 0.0637 and accuracy of 0.991\n",
      "Epoch 739, Overall loss = 0.052 and accuracy of 0.994\n",
      "Epoch 740, Overall loss = 0.0583 and accuracy of 0.996\n",
      "Epoch 741, Overall loss = 0.0547 and accuracy of 0.995\n",
      "Epoch 742, Overall loss = 0.0442 and accuracy of 0.994\n",
      "Epoch 743, Overall loss = 0.047 and accuracy of 0.995\n",
      "Epoch 744, Overall loss = 0.0622 and accuracy of 0.991\n",
      "Epoch 745, Overall loss = 0.0631 and accuracy of 0.99\n",
      "Epoch 746, Overall loss = 0.0661 and accuracy of 0.991\n",
      "Epoch 747, Overall loss = 0.0591 and accuracy of 0.991\n",
      "Epoch 748, Overall loss = 0.0678 and accuracy of 0.991\n",
      "Epoch 749, Overall loss = 0.0508 and accuracy of 0.996\n",
      "Epoch 750, Overall loss = 0.0598 and accuracy of 0.989\n",
      "Iteration1500: with minibatch training loss = 0.0534 and accuracy of 0.99\n",
      "Epoch 751, Overall loss = 0.0575 and accuracy of 0.993\n",
      "Epoch 752, Overall loss = 0.0525 and accuracy of 0.994\n",
      "Epoch 753, Overall loss = 0.0487 and accuracy of 0.995\n",
      "Epoch 754, Overall loss = 0.057 and accuracy of 0.989\n",
      "Epoch 755, Overall loss = 0.0533 and accuracy of 0.995\n",
      "Epoch 756, Overall loss = 0.0608 and accuracy of 0.994\n",
      "Epoch 757, Overall loss = 0.06 and accuracy of 0.996\n",
      "Epoch 758, Overall loss = 0.0619 and accuracy of 0.991\n",
      "Epoch 759, Overall loss = 0.0682 and accuracy of 0.988\n",
      "Epoch 760, Overall loss = 0.0619 and accuracy of 0.99\n",
      "Epoch 761, Overall loss = 0.0395 and accuracy of 0.995\n",
      "Epoch 762, Overall loss = 0.0651 and accuracy of 0.991\n",
      "Epoch 763, Overall loss = 0.0571 and accuracy of 0.993\n",
      "Epoch 764, Overall loss = 0.0417 and accuracy of 0.996\n",
      "Epoch 765, Overall loss = 0.0554 and accuracy of 0.994\n",
      "Epoch 766, Overall loss = 0.0503 and accuracy of 0.993\n",
      "Epoch 767, Overall loss = 0.0374 and accuracy of 0.998\n",
      "Epoch 768, Overall loss = 0.0563 and accuracy of 0.993\n",
      "Epoch 769, Overall loss = 0.0459 and accuracy of 0.995\n",
      "Epoch 770, Overall loss = 0.0584 and accuracy of 0.99\n",
      "Epoch 771, Overall loss = 0.0634 and accuracy of 0.994\n",
      "Epoch 772, Overall loss = 0.0551 and accuracy of 0.996\n",
      "Epoch 773, Overall loss = 0.0534 and accuracy of 0.998\n",
      "Epoch 774, Overall loss = 0.0575 and accuracy of 0.994\n",
      "Epoch 775, Overall loss = 0.0412 and accuracy of 0.996\n",
      "Epoch 776, Overall loss = 0.0454 and accuracy of 0.996\n",
      "Epoch 777, Overall loss = 0.0548 and accuracy of 0.991\n",
      "Epoch 778, Overall loss = 0.0382 and accuracy of 0.999\n",
      "Epoch 779, Overall loss = 0.0389 and accuracy of 0.998\n",
      "Epoch 780, Overall loss = 0.0577 and accuracy of 0.995\n",
      "Epoch 781, Overall loss = 0.0545 and accuracy of 0.994\n",
      "Epoch 782, Overall loss = 0.0601 and accuracy of 0.993\n",
      "Epoch 783, Overall loss = 0.0487 and accuracy of 0.996\n",
      "Epoch 784, Overall loss = 0.0428 and accuracy of 0.999\n",
      "Epoch 785, Overall loss = 0.0561 and accuracy of 0.989\n",
      "Epoch 786, Overall loss = 0.0519 and accuracy of 0.993\n",
      "Epoch 787, Overall loss = 0.0488 and accuracy of 0.996\n",
      "Epoch 788, Overall loss = 0.0623 and accuracy of 0.989\n",
      "Epoch 789, Overall loss = 0.0428 and accuracy of 0.995\n",
      "Epoch 790, Overall loss = 0.061 and accuracy of 0.993\n",
      "Epoch 791, Overall loss = 0.0545 and accuracy of 0.989\n",
      "Epoch 792, Overall loss = 0.0515 and accuracy of 0.994\n",
      "Epoch 793, Overall loss = 0.0551 and accuracy of 0.996\n",
      "Epoch 794, Overall loss = 0.0462 and accuracy of 0.994\n",
      "Epoch 795, Overall loss = 0.0522 and accuracy of 0.991\n",
      "Epoch 796, Overall loss = 0.0487 and accuracy of 0.994\n",
      "Epoch 797, Overall loss = 0.0542 and accuracy of 0.993\n",
      "Epoch 798, Overall loss = 0.0435 and accuracy of 0.996\n",
      "Epoch 799, Overall loss = 0.0478 and accuracy of 0.995\n",
      "Epoch 800, Overall loss = 0.0503 and accuracy of 0.995\n",
      "Iteration1600: with minibatch training loss = 0.0516 and accuracy of 0.99\n",
      "Epoch 801, Overall loss = 0.058 and accuracy of 0.991\n",
      "Epoch 802, Overall loss = 0.055 and accuracy of 0.991\n",
      "Epoch 803, Overall loss = 0.0406 and accuracy of 0.996\n",
      "Epoch 804, Overall loss = 0.0436 and accuracy of 0.99\n",
      "Epoch 805, Overall loss = 0.0488 and accuracy of 0.995\n",
      "Epoch 806, Overall loss = 0.0424 and accuracy of 0.996\n",
      "Epoch 807, Overall loss = 0.0447 and accuracy of 0.995\n",
      "Epoch 808, Overall loss = 0.0519 and accuracy of 0.995\n",
      "Epoch 809, Overall loss = 0.0632 and accuracy of 0.989\n",
      "Epoch 810, Overall loss = 0.0482 and accuracy of 0.991\n",
      "Epoch 811, Overall loss = 0.052 and accuracy of 0.993\n",
      "Epoch 812, Overall loss = 0.0529 and accuracy of 0.99\n",
      "Epoch 813, Overall loss = 0.0415 and accuracy of 0.998\n",
      "Epoch 814, Overall loss = 0.0541 and accuracy of 0.993\n",
      "Epoch 815, Overall loss = 0.0601 and accuracy of 0.99\n",
      "Epoch 816, Overall loss = 0.0525 and accuracy of 0.995\n",
      "Epoch 817, Overall loss = 0.0623 and accuracy of 0.99\n",
      "Epoch 818, Overall loss = 0.0709 and accuracy of 0.985\n",
      "Epoch 819, Overall loss = 0.0521 and accuracy of 0.995\n",
      "Epoch 820, Overall loss = 0.0634 and accuracy of 0.989\n",
      "Epoch 821, Overall loss = 0.0666 and accuracy of 0.99\n",
      "Epoch 822, Overall loss = 0.0467 and accuracy of 0.995\n",
      "Epoch 823, Overall loss = 0.0533 and accuracy of 0.994\n",
      "Epoch 824, Overall loss = 0.0496 and accuracy of 0.994\n",
      "Epoch 825, Overall loss = 0.0536 and accuracy of 0.995\n",
      "Epoch 826, Overall loss = 0.0535 and accuracy of 0.993\n",
      "Epoch 827, Overall loss = 0.0621 and accuracy of 0.991\n",
      "Epoch 828, Overall loss = 0.0409 and accuracy of 0.998\n",
      "Epoch 829, Overall loss = 0.0561 and accuracy of 0.99\n",
      "Epoch 830, Overall loss = 0.0676 and accuracy of 0.99\n",
      "Epoch 831, Overall loss = 0.0445 and accuracy of 0.994\n",
      "Epoch 832, Overall loss = 0.0417 and accuracy of 0.998\n",
      "Epoch 833, Overall loss = 0.0507 and accuracy of 0.995\n",
      "Epoch 834, Overall loss = 0.0618 and accuracy of 0.993\n",
      "Epoch 835, Overall loss = 0.0473 and accuracy of 0.995\n",
      "Epoch 836, Overall loss = 0.0492 and accuracy of 0.993\n",
      "Epoch 837, Overall loss = 0.0447 and accuracy of 0.995\n",
      "Epoch 838, Overall loss = 0.0578 and accuracy of 0.991\n",
      "Epoch 839, Overall loss = 0.0665 and accuracy of 0.988\n",
      "Epoch 840, Overall loss = 0.0566 and accuracy of 0.993\n",
      "Epoch 841, Overall loss = 0.0657 and accuracy of 0.989\n",
      "Epoch 842, Overall loss = 0.0503 and accuracy of 0.993\n",
      "Epoch 843, Overall loss = 0.0498 and accuracy of 0.994\n",
      "Epoch 844, Overall loss = 0.0627 and accuracy of 0.988\n",
      "Epoch 845, Overall loss = 0.0423 and accuracy of 0.996\n",
      "Epoch 846, Overall loss = 0.0505 and accuracy of 0.991\n",
      "Epoch 847, Overall loss = 0.0627 and accuracy of 0.991\n",
      "Epoch 848, Overall loss = 0.0742 and accuracy of 0.989\n",
      "Epoch 849, Overall loss = 0.0518 and accuracy of 0.994\n",
      "Epoch 850, Overall loss = 0.0663 and accuracy of 0.994\n",
      "Iteration1700: with minibatch training loss = 0.0779 and accuracy of 0.99\n",
      "Epoch 851, Overall loss = 0.0724 and accuracy of 0.986\n",
      "Epoch 852, Overall loss = 0.0663 and accuracy of 0.99\n",
      "Epoch 853, Overall loss = 0.0469 and accuracy of 0.996\n",
      "Epoch 854, Overall loss = 0.0523 and accuracy of 0.991\n",
      "Epoch 855, Overall loss = 0.0485 and accuracy of 0.994\n",
      "Epoch 856, Overall loss = 0.0411 and accuracy of 0.998\n",
      "Epoch 857, Overall loss = 0.0494 and accuracy of 0.994\n",
      "Epoch 858, Overall loss = 0.0479 and accuracy of 0.996\n",
      "Epoch 859, Overall loss = 0.0554 and accuracy of 0.993\n",
      "Epoch 860, Overall loss = 0.0409 and accuracy of 0.995\n",
      "Epoch 861, Overall loss = 0.0666 and accuracy of 0.989\n",
      "Epoch 862, Overall loss = 0.0509 and accuracy of 0.995\n",
      "Epoch 863, Overall loss = 0.0591 and accuracy of 0.995\n",
      "Epoch 864, Overall loss = 0.062 and accuracy of 0.989\n",
      "Epoch 865, Overall loss = 0.0517 and accuracy of 0.993\n",
      "Epoch 866, Overall loss = 0.0653 and accuracy of 0.989\n",
      "Epoch 867, Overall loss = 0.0588 and accuracy of 0.99\n",
      "Epoch 868, Overall loss = 0.045 and accuracy of 0.996\n",
      "Epoch 869, Overall loss = 0.0512 and accuracy of 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870, Overall loss = 0.0542 and accuracy of 0.996\n",
      "Epoch 871, Overall loss = 0.052 and accuracy of 0.993\n",
      "Epoch 872, Overall loss = 0.0534 and accuracy of 0.994\n",
      "Epoch 873, Overall loss = 0.0498 and accuracy of 0.99\n",
      "Epoch 874, Overall loss = 0.0519 and accuracy of 0.993\n",
      "Epoch 875, Overall loss = 0.0567 and accuracy of 0.994\n",
      "Epoch 876, Overall loss = 0.0445 and accuracy of 0.994\n",
      "Epoch 877, Overall loss = 0.0672 and accuracy of 0.989\n",
      "Epoch 878, Overall loss = 0.0514 and accuracy of 0.993\n",
      "Epoch 879, Overall loss = 0.0349 and accuracy of 1\n",
      "Epoch 880, Overall loss = 0.0408 and accuracy of 0.999\n",
      "Epoch 881, Overall loss = 0.0631 and accuracy of 0.99\n",
      "Epoch 882, Overall loss = 0.0478 and accuracy of 0.995\n",
      "Epoch 883, Overall loss = 0.0445 and accuracy of 0.995\n",
      "Epoch 884, Overall loss = 0.0518 and accuracy of 0.996\n",
      "Epoch 885, Overall loss = 0.062 and accuracy of 0.993\n",
      "Epoch 886, Overall loss = 0.0413 and accuracy of 0.996\n",
      "Epoch 887, Overall loss = 0.041 and accuracy of 0.998\n",
      "Epoch 888, Overall loss = 0.0564 and accuracy of 0.993\n",
      "Epoch 889, Overall loss = 0.0399 and accuracy of 0.998\n",
      "Epoch 890, Overall loss = 0.0472 and accuracy of 0.99\n",
      "Epoch 891, Overall loss = 0.0404 and accuracy of 0.996\n",
      "Epoch 892, Overall loss = 0.0395 and accuracy of 0.996\n",
      "Epoch 893, Overall loss = 0.0385 and accuracy of 0.996\n",
      "Epoch 894, Overall loss = 0.0414 and accuracy of 0.995\n",
      "Epoch 895, Overall loss = 0.0385 and accuracy of 0.996\n",
      "Epoch 896, Overall loss = 0.0569 and accuracy of 0.994\n",
      "Epoch 897, Overall loss = 0.0479 and accuracy of 0.994\n",
      "Epoch 898, Overall loss = 0.046 and accuracy of 0.993\n",
      "Epoch 899, Overall loss = 0.0404 and accuracy of 0.998\n",
      "Epoch 900, Overall loss = 0.051 and accuracy of 0.988\n",
      "Iteration1800: with minibatch training loss = 0.0497 and accuracy of 0.99\n",
      "Epoch 901, Overall loss = 0.0419 and accuracy of 0.996\n",
      "Epoch 902, Overall loss = 0.0593 and accuracy of 0.991\n",
      "Epoch 903, Overall loss = 0.0459 and accuracy of 0.996\n",
      "Epoch 904, Overall loss = 0.0348 and accuracy of 0.999\n",
      "Epoch 905, Overall loss = 0.0435 and accuracy of 0.993\n",
      "Epoch 906, Overall loss = 0.0409 and accuracy of 0.995\n",
      "Epoch 907, Overall loss = 0.0517 and accuracy of 0.993\n",
      "Epoch 908, Overall loss = 0.0481 and accuracy of 0.995\n",
      "Epoch 909, Overall loss = 0.0329 and accuracy of 0.998\n",
      "Epoch 910, Overall loss = 0.0458 and accuracy of 0.995\n",
      "Epoch 911, Overall loss = 0.0481 and accuracy of 0.991\n",
      "Epoch 912, Overall loss = 0.0364 and accuracy of 0.996\n",
      "Epoch 913, Overall loss = 0.052 and accuracy of 0.994\n",
      "Epoch 914, Overall loss = 0.0437 and accuracy of 0.994\n",
      "Epoch 915, Overall loss = 0.0382 and accuracy of 0.995\n",
      "Epoch 916, Overall loss = 0.0392 and accuracy of 0.998\n",
      "Epoch 917, Overall loss = 0.0428 and accuracy of 0.995\n",
      "Epoch 918, Overall loss = 0.0352 and accuracy of 0.999\n",
      "Epoch 919, Overall loss = 0.0407 and accuracy of 0.995\n",
      "Epoch 920, Overall loss = 0.0519 and accuracy of 0.99\n",
      "Epoch 921, Overall loss = 0.0419 and accuracy of 0.995\n",
      "Epoch 922, Overall loss = 0.05 and accuracy of 0.993\n",
      "Epoch 923, Overall loss = 0.0428 and accuracy of 0.994\n",
      "Epoch 924, Overall loss = 0.0357 and accuracy of 0.996\n",
      "Epoch 925, Overall loss = 0.0464 and accuracy of 0.991\n",
      "Epoch 926, Overall loss = 0.0459 and accuracy of 0.994\n",
      "Epoch 927, Overall loss = 0.0662 and accuracy of 0.988\n",
      "Epoch 928, Overall loss = 0.0717 and accuracy of 0.988\n",
      "Epoch 929, Overall loss = 0.0466 and accuracy of 0.996\n",
      "Epoch 930, Overall loss = 0.0482 and accuracy of 0.998\n",
      "Epoch 931, Overall loss = 0.0676 and accuracy of 0.989\n",
      "Epoch 932, Overall loss = 0.0427 and accuracy of 0.994\n",
      "Epoch 933, Overall loss = 0.0489 and accuracy of 0.995\n",
      "Epoch 934, Overall loss = 0.0466 and accuracy of 0.995\n",
      "Epoch 935, Overall loss = 0.0525 and accuracy of 0.993\n",
      "Epoch 936, Overall loss = 0.0573 and accuracy of 0.995\n",
      "Epoch 937, Overall loss = 0.0355 and accuracy of 0.996\n",
      "Epoch 938, Overall loss = 0.0408 and accuracy of 0.998\n",
      "Epoch 939, Overall loss = 0.0525 and accuracy of 0.995\n",
      "Epoch 940, Overall loss = 0.0461 and accuracy of 0.991\n",
      "Epoch 941, Overall loss = 0.0452 and accuracy of 0.995\n",
      "Epoch 942, Overall loss = 0.0486 and accuracy of 0.993\n",
      "Epoch 943, Overall loss = 0.048 and accuracy of 0.993\n",
      "Epoch 944, Overall loss = 0.0625 and accuracy of 0.988\n",
      "Epoch 945, Overall loss = 0.0433 and accuracy of 0.994\n",
      "Epoch 946, Overall loss = 0.0407 and accuracy of 0.998\n",
      "Epoch 947, Overall loss = 0.0608 and accuracy of 0.993\n",
      "Epoch 948, Overall loss = 0.0516 and accuracy of 0.991\n",
      "Epoch 949, Overall loss = 0.0478 and accuracy of 0.994\n",
      "Epoch 950, Overall loss = 0.0507 and accuracy of 0.995\n",
      "Iteration1900: with minibatch training loss = 0.0685 and accuracy of 0.99\n",
      "Epoch 951, Overall loss = 0.0552 and accuracy of 0.993\n",
      "Epoch 952, Overall loss = 0.0517 and accuracy of 0.99\n",
      "Epoch 953, Overall loss = 0.06 and accuracy of 0.99\n",
      "Epoch 954, Overall loss = 0.0419 and accuracy of 0.996\n",
      "Epoch 955, Overall loss = 0.052 and accuracy of 0.993\n",
      "Epoch 956, Overall loss = 0.0647 and accuracy of 0.991\n",
      "Epoch 957, Overall loss = 0.0556 and accuracy of 0.991\n",
      "Epoch 958, Overall loss = 0.0498 and accuracy of 0.993\n",
      "Epoch 959, Overall loss = 0.052 and accuracy of 0.99\n",
      "Epoch 960, Overall loss = 0.057 and accuracy of 0.988\n",
      "Epoch 961, Overall loss = 0.0634 and accuracy of 0.989\n",
      "Epoch 962, Overall loss = 0.0601 and accuracy of 0.989\n",
      "Epoch 963, Overall loss = 0.0379 and accuracy of 0.998\n",
      "Epoch 964, Overall loss = 0.0665 and accuracy of 0.989\n",
      "Epoch 965, Overall loss = 0.0399 and accuracy of 0.996\n",
      "Epoch 966, Overall loss = 0.06 and accuracy of 0.994\n",
      "Epoch 967, Overall loss = 0.0357 and accuracy of 0.998\n",
      "Epoch 968, Overall loss = 0.0648 and accuracy of 0.99\n",
      "Epoch 969, Overall loss = 0.0572 and accuracy of 0.993\n",
      "Epoch 970, Overall loss = 0.0449 and accuracy of 0.995\n",
      "Epoch 971, Overall loss = 0.0421 and accuracy of 0.995\n",
      "Epoch 972, Overall loss = 0.0591 and accuracy of 0.993\n",
      "Epoch 973, Overall loss = 0.0527 and accuracy of 0.989\n",
      "Epoch 974, Overall loss = 0.054 and accuracy of 0.995\n",
      "Epoch 975, Overall loss = 0.0576 and accuracy of 0.993\n",
      "Epoch 976, Overall loss = 0.0446 and accuracy of 0.998\n",
      "Epoch 977, Overall loss = 0.0554 and accuracy of 0.991\n",
      "Epoch 978, Overall loss = 0.0776 and accuracy of 0.984\n",
      "Epoch 979, Overall loss = 0.0711 and accuracy of 0.988\n",
      "Epoch 980, Overall loss = 0.0636 and accuracy of 0.99\n",
      "Epoch 981, Overall loss = 0.0863 and accuracy of 0.981\n",
      "Epoch 982, Overall loss = 0.0581 and accuracy of 0.993\n",
      "Epoch 983, Overall loss = 0.0622 and accuracy of 0.993\n",
      "Epoch 984, Overall loss = 0.0675 and accuracy of 0.991\n",
      "Epoch 985, Overall loss = 0.0547 and accuracy of 0.99\n",
      "Epoch 986, Overall loss = 0.0675 and accuracy of 0.989\n",
      "Epoch 987, Overall loss = 0.0756 and accuracy of 0.988\n",
      "Epoch 988, Overall loss = 0.0526 and accuracy of 0.993\n",
      "Epoch 989, Overall loss = 0.0729 and accuracy of 0.986\n",
      "Epoch 990, Overall loss = 0.0675 and accuracy of 0.986\n",
      "Epoch 991, Overall loss = 0.062 and accuracy of 0.993\n",
      "Epoch 992, Overall loss = 0.0788 and accuracy of 0.99\n",
      "Epoch 993, Overall loss = 0.0911 and accuracy of 0.986\n",
      "Epoch 994, Overall loss = 0.0642 and accuracy of 0.991\n",
      "Epoch 995, Overall loss = 0.0964 and accuracy of 0.975\n",
      "Epoch 996, Overall loss = 0.0602 and accuracy of 0.991\n",
      "Epoch 997, Overall loss = 0.072 and accuracy of 0.989\n",
      "Epoch 998, Overall loss = 0.0593 and accuracy of 0.993\n",
      "Epoch 999, Overall loss = 0.0708 and accuracy of 0.988\n",
      "Epoch 1000, Overall loss = 0.074 and accuracy of 0.988\n",
      "Iteration2000: with minibatch training loss = 0.0759 and accuracy of 0.99\n",
      "Epoch 1001, Overall loss = 0.0715 and accuracy of 0.989\n",
      "Epoch 1002, Overall loss = 0.0588 and accuracy of 0.99\n",
      "Epoch 1003, Overall loss = 0.0521 and accuracy of 0.994\n",
      "Epoch 1004, Overall loss = 0.0523 and accuracy of 0.99\n",
      "Epoch 1005, Overall loss = 0.0647 and accuracy of 0.991\n",
      "Epoch 1006, Overall loss = 0.0653 and accuracy of 0.986\n",
      "Epoch 1007, Overall loss = 0.0695 and accuracy of 0.986\n",
      "Epoch 1008, Overall loss = 0.0607 and accuracy of 0.993\n",
      "Epoch 1009, Overall loss = 0.0702 and accuracy of 0.986\n",
      "Epoch 1010, Overall loss = 0.0515 and accuracy of 0.991\n",
      "Epoch 1011, Overall loss = 0.0496 and accuracy of 0.991\n",
      "Epoch 1012, Overall loss = 0.0783 and accuracy of 0.981\n",
      "Epoch 1013, Overall loss = 0.0406 and accuracy of 0.998\n",
      "Epoch 1014, Overall loss = 0.105 and accuracy of 0.979\n",
      "Epoch 1015, Overall loss = 0.0699 and accuracy of 0.99\n",
      "Epoch 1016, Overall loss = 0.0871 and accuracy of 0.98\n",
      "Epoch 1017, Overall loss = 0.0778 and accuracy of 0.983\n",
      "Epoch 1018, Overall loss = 0.0939 and accuracy of 0.981\n",
      "Epoch 1019, Overall loss = 0.0711 and accuracy of 0.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1020, Overall loss = 0.0752 and accuracy of 0.988\n",
      "Epoch 1021, Overall loss = 0.0708 and accuracy of 0.989\n",
      "Epoch 1022, Overall loss = 0.0772 and accuracy of 0.985\n",
      "Epoch 1023, Overall loss = 0.0622 and accuracy of 0.991\n",
      "Epoch 1024, Overall loss = 0.0947 and accuracy of 0.985\n",
      "Epoch 1025, Overall loss = 0.0815 and accuracy of 0.988\n",
      "Epoch 1026, Overall loss = 0.0669 and accuracy of 0.99\n",
      "Epoch 1027, Overall loss = 0.07 and accuracy of 0.993\n",
      "Epoch 1028, Overall loss = 0.0576 and accuracy of 0.994\n",
      "Epoch 1029, Overall loss = 0.0582 and accuracy of 0.989\n",
      "Epoch 1030, Overall loss = 0.0625 and accuracy of 0.991\n",
      "Epoch 1031, Overall loss = 0.07 and accuracy of 0.99\n",
      "Epoch 1032, Overall loss = 0.0435 and accuracy of 0.996\n",
      "Epoch 1033, Overall loss = 0.0723 and accuracy of 0.99\n",
      "Epoch 1034, Overall loss = 0.0556 and accuracy of 0.993\n",
      "Epoch 1035, Overall loss = 0.0904 and accuracy of 0.985\n",
      "Epoch 1036, Overall loss = 0.0592 and accuracy of 0.989\n",
      "Epoch 1037, Overall loss = 0.0503 and accuracy of 0.994\n",
      "Epoch 1038, Overall loss = 0.0532 and accuracy of 0.995\n",
      "Epoch 1039, Overall loss = 0.0758 and accuracy of 0.985\n",
      "Epoch 1040, Overall loss = 0.0597 and accuracy of 0.989\n",
      "Epoch 1041, Overall loss = 0.0731 and accuracy of 0.988\n",
      "Epoch 1042, Overall loss = 0.0692 and accuracy of 0.989\n",
      "Epoch 1043, Overall loss = 0.0734 and accuracy of 0.988\n",
      "Epoch 1044, Overall loss = 0.0614 and accuracy of 0.988\n",
      "Epoch 1045, Overall loss = 0.0507 and accuracy of 0.995\n",
      "Epoch 1046, Overall loss = 0.0738 and accuracy of 0.989\n",
      "Epoch 1047, Overall loss = 0.0564 and accuracy of 0.993\n",
      "Epoch 1048, Overall loss = 0.049 and accuracy of 0.993\n",
      "Epoch 1049, Overall loss = 0.0477 and accuracy of 0.993\n",
      "Epoch 1050, Overall loss = 0.0699 and accuracy of 0.988\n",
      "Iteration2100: with minibatch training loss = 0.0678 and accuracy of 0.99\n",
      "Epoch 1051, Overall loss = 0.0559 and accuracy of 0.993\n",
      "Epoch 1052, Overall loss = 0.0581 and accuracy of 0.993\n",
      "Epoch 1053, Overall loss = 0.0593 and accuracy of 0.99\n",
      "Epoch 1054, Overall loss = 0.0494 and accuracy of 0.993\n",
      "Epoch 1055, Overall loss = 0.0551 and accuracy of 0.994\n",
      "Epoch 1056, Overall loss = 0.0477 and accuracy of 0.99\n",
      "Epoch 1057, Overall loss = 0.0597 and accuracy of 0.986\n",
      "Epoch 1058, Overall loss = 0.0635 and accuracy of 0.99\n",
      "Epoch 1059, Overall loss = 0.0595 and accuracy of 0.993\n",
      "Epoch 1060, Overall loss = 0.0727 and accuracy of 0.988\n",
      "Epoch 1061, Overall loss = 0.0525 and accuracy of 0.994\n",
      "Epoch 1062, Overall loss = 0.0399 and accuracy of 0.996\n",
      "Epoch 1063, Overall loss = 0.0457 and accuracy of 0.994\n",
      "Epoch 1064, Overall loss = 0.0553 and accuracy of 0.993\n",
      "Epoch 1065, Overall loss = 0.0538 and accuracy of 0.993\n",
      "Epoch 1066, Overall loss = 0.0616 and accuracy of 0.993\n",
      "Epoch 1067, Overall loss = 0.043 and accuracy of 0.995\n",
      "Epoch 1068, Overall loss = 0.0609 and accuracy of 0.993\n",
      "Epoch 1069, Overall loss = 0.0476 and accuracy of 0.994\n",
      "Epoch 1070, Overall loss = 0.0859 and accuracy of 0.985\n",
      "Epoch 1071, Overall loss = 0.066 and accuracy of 0.99\n",
      "Epoch 1072, Overall loss = 0.0566 and accuracy of 0.993\n",
      "Epoch 1073, Overall loss = 0.073 and accuracy of 0.99\n",
      "Epoch 1074, Overall loss = 0.0514 and accuracy of 0.994\n",
      "Epoch 1075, Overall loss = 0.0645 and accuracy of 0.99\n",
      "Epoch 1076, Overall loss = 0.0538 and accuracy of 0.991\n",
      "Epoch 1077, Overall loss = 0.0418 and accuracy of 0.995\n",
      "Epoch 1078, Overall loss = 0.0503 and accuracy of 0.994\n",
      "Epoch 1079, Overall loss = 0.0561 and accuracy of 0.991\n",
      "Epoch 1080, Overall loss = 0.0571 and accuracy of 0.99\n",
      "Epoch 1081, Overall loss = 0.0633 and accuracy of 0.991\n",
      "Epoch 1082, Overall loss = 0.0813 and accuracy of 0.988\n",
      "Epoch 1083, Overall loss = 0.0668 and accuracy of 0.986\n",
      "Epoch 1084, Overall loss = 0.0788 and accuracy of 0.986\n",
      "Epoch 1085, Overall loss = 0.074 and accuracy of 0.985\n",
      "Epoch 1086, Overall loss = 0.0427 and accuracy of 0.996\n",
      "Epoch 1087, Overall loss = 0.0533 and accuracy of 0.993\n",
      "Epoch 1088, Overall loss = 0.0545 and accuracy of 0.995\n",
      "Epoch 1089, Overall loss = 0.0447 and accuracy of 0.991\n",
      "Epoch 1090, Overall loss = 0.0641 and accuracy of 0.99\n",
      "Epoch 1091, Overall loss = 0.0459 and accuracy of 0.993\n",
      "Epoch 1092, Overall loss = 0.0475 and accuracy of 0.995\n",
      "Epoch 1093, Overall loss = 0.0405 and accuracy of 0.995\n",
      "Epoch 1094, Overall loss = 0.0403 and accuracy of 0.994\n",
      "Epoch 1095, Overall loss = 0.0363 and accuracy of 0.998\n",
      "Epoch 1096, Overall loss = 0.0627 and accuracy of 0.991\n",
      "Epoch 1097, Overall loss = 0.0561 and accuracy of 0.991\n",
      "Epoch 1098, Overall loss = 0.0481 and accuracy of 0.993\n",
      "Epoch 1099, Overall loss = 0.0393 and accuracy of 0.998\n",
      "Epoch 1100, Overall loss = 0.051 and accuracy of 0.994\n",
      "Iteration2200: with minibatch training loss = 0.0329 and accuracy of 1\n",
      "Epoch 1101, Overall loss = 0.0414 and accuracy of 0.991\n",
      "Epoch 1102, Overall loss = 0.0494 and accuracy of 0.995\n",
      "Epoch 1103, Overall loss = 0.0482 and accuracy of 0.993\n",
      "Epoch 1104, Overall loss = 0.042 and accuracy of 0.995\n",
      "Epoch 1105, Overall loss = 0.0438 and accuracy of 0.998\n",
      "Epoch 1106, Overall loss = 0.0804 and accuracy of 0.989\n",
      "Epoch 1107, Overall loss = 0.0485 and accuracy of 0.994\n",
      "Epoch 1108, Overall loss = 0.0488 and accuracy of 0.993\n",
      "Epoch 1109, Overall loss = 0.0632 and accuracy of 0.989\n",
      "Epoch 1110, Overall loss = 0.0732 and accuracy of 0.985\n",
      "Epoch 1111, Overall loss = 0.0648 and accuracy of 0.985\n",
      "Epoch 1112, Overall loss = 0.065 and accuracy of 0.988\n",
      "Epoch 1113, Overall loss = 0.0878 and accuracy of 0.984\n",
      "Epoch 1114, Overall loss = 0.0435 and accuracy of 0.991\n",
      "Epoch 1115, Overall loss = 0.0516 and accuracy of 0.99\n",
      "Epoch 1116, Overall loss = 0.0834 and accuracy of 0.983\n",
      "Epoch 1117, Overall loss = 0.0589 and accuracy of 0.991\n",
      "Epoch 1118, Overall loss = 0.0628 and accuracy of 0.99\n",
      "Epoch 1119, Overall loss = 0.0709 and accuracy of 0.989\n",
      "Epoch 1120, Overall loss = 0.0613 and accuracy of 0.989\n",
      "Epoch 1121, Overall loss = 0.0654 and accuracy of 0.988\n",
      "Epoch 1122, Overall loss = 0.0594 and accuracy of 0.991\n",
      "Epoch 1123, Overall loss = 0.0637 and accuracy of 0.988\n",
      "Epoch 1124, Overall loss = 0.06 and accuracy of 0.989\n",
      "Epoch 1125, Overall loss = 0.0433 and accuracy of 0.996\n",
      "Epoch 1126, Overall loss = 0.0693 and accuracy of 0.989\n",
      "Epoch 1127, Overall loss = 0.0472 and accuracy of 0.996\n",
      "Epoch 1128, Overall loss = 0.0792 and accuracy of 0.988\n",
      "Epoch 1129, Overall loss = 0.0588 and accuracy of 0.99\n",
      "Epoch 1130, Overall loss = 0.0818 and accuracy of 0.983\n",
      "Epoch 1131, Overall loss = 0.0655 and accuracy of 0.99\n",
      "Epoch 1132, Overall loss = 0.104 and accuracy of 0.984\n",
      "Epoch 1133, Overall loss = 0.0646 and accuracy of 0.986\n",
      "Epoch 1134, Overall loss = 0.0601 and accuracy of 0.988\n",
      "Epoch 1135, Overall loss = 0.0476 and accuracy of 0.993\n",
      "Epoch 1136, Overall loss = 0.0603 and accuracy of 0.988\n",
      "Epoch 1137, Overall loss = 0.0537 and accuracy of 0.993\n",
      "Epoch 1138, Overall loss = 0.0776 and accuracy of 0.979\n",
      "Epoch 1139, Overall loss = 0.0771 and accuracy of 0.989\n",
      "Epoch 1140, Overall loss = 0.0609 and accuracy of 0.989\n",
      "Epoch 1141, Overall loss = 0.0653 and accuracy of 0.993\n",
      "Epoch 1142, Overall loss = 0.0711 and accuracy of 0.99\n",
      "Epoch 1143, Overall loss = 0.0679 and accuracy of 0.99\n",
      "Epoch 1144, Overall loss = 0.0481 and accuracy of 0.994\n",
      "Epoch 1145, Overall loss = 0.0755 and accuracy of 0.984\n",
      "Epoch 1146, Overall loss = 0.0834 and accuracy of 0.983\n",
      "Epoch 1147, Overall loss = 0.0817 and accuracy of 0.984\n",
      "Epoch 1148, Overall loss = 0.0713 and accuracy of 0.985\n",
      "Epoch 1149, Overall loss = 0.0988 and accuracy of 0.984\n",
      "Epoch 1150, Overall loss = 0.0567 and accuracy of 0.99\n",
      "Iteration2300: with minibatch training loss = 0.069 and accuracy of 0.99\n",
      "Epoch 1151, Overall loss = 0.0616 and accuracy of 0.99\n",
      "Epoch 1152, Overall loss = 0.0524 and accuracy of 0.993\n",
      "Epoch 1153, Overall loss = 0.0693 and accuracy of 0.984\n",
      "Epoch 1154, Overall loss = 0.0707 and accuracy of 0.985\n",
      "Epoch 1155, Overall loss = 0.0614 and accuracy of 0.99\n",
      "Epoch 1156, Overall loss = 0.0617 and accuracy of 0.993\n",
      "Epoch 1157, Overall loss = 0.0932 and accuracy of 0.986\n",
      "Epoch 1158, Overall loss = 0.0655 and accuracy of 0.991\n",
      "Epoch 1159, Overall loss = 0.0675 and accuracy of 0.99\n",
      "Epoch 1160, Overall loss = 0.0552 and accuracy of 0.989\n",
      "Epoch 1161, Overall loss = 0.0512 and accuracy of 0.991\n",
      "Epoch 1162, Overall loss = 0.06 and accuracy of 0.988\n",
      "Epoch 1163, Overall loss = 0.0738 and accuracy of 0.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1164, Overall loss = 0.0516 and accuracy of 0.993\n",
      "Epoch 1165, Overall loss = 0.0675 and accuracy of 0.986\n",
      "Epoch 1166, Overall loss = 0.0686 and accuracy of 0.99\n",
      "Epoch 1167, Overall loss = 0.0494 and accuracy of 0.991\n",
      "Epoch 1168, Overall loss = 0.0542 and accuracy of 0.989\n",
      "Epoch 1169, Overall loss = 0.0637 and accuracy of 0.991\n",
      "Epoch 1170, Overall loss = 0.0651 and accuracy of 0.99\n",
      "Epoch 1171, Overall loss = 0.0453 and accuracy of 0.995\n",
      "Epoch 1172, Overall loss = 0.0509 and accuracy of 0.991\n",
      "Epoch 1173, Overall loss = 0.0564 and accuracy of 0.993\n",
      "Epoch 1174, Overall loss = 0.0379 and accuracy of 0.996\n",
      "Epoch 1175, Overall loss = 0.0498 and accuracy of 0.994\n",
      "Epoch 1176, Overall loss = 0.0399 and accuracy of 0.996\n",
      "Epoch 1177, Overall loss = 0.0623 and accuracy of 0.991\n",
      "Epoch 1178, Overall loss = 0.0539 and accuracy of 0.991\n",
      "Epoch 1179, Overall loss = 0.0649 and accuracy of 0.986\n",
      "Epoch 1180, Overall loss = 0.0712 and accuracy of 0.989\n",
      "Epoch 1181, Overall loss = 0.0483 and accuracy of 0.991\n",
      "Epoch 1182, Overall loss = 0.0899 and accuracy of 0.983\n",
      "Epoch 1183, Overall loss = 0.0488 and accuracy of 0.995\n",
      "Epoch 1184, Overall loss = 0.0541 and accuracy of 0.99\n",
      "Epoch 1185, Overall loss = 0.0646 and accuracy of 0.989\n",
      "Epoch 1186, Overall loss = 0.0523 and accuracy of 0.993\n",
      "Epoch 1187, Overall loss = 0.0529 and accuracy of 0.99\n",
      "Epoch 1188, Overall loss = 0.0677 and accuracy of 0.989\n",
      "Epoch 1189, Overall loss = 0.052 and accuracy of 0.991\n",
      "Epoch 1190, Overall loss = 0.0524 and accuracy of 0.991\n",
      "Epoch 1191, Overall loss = 0.0456 and accuracy of 0.993\n",
      "Epoch 1192, Overall loss = 0.0525 and accuracy of 0.99\n",
      "Epoch 1193, Overall loss = 0.046 and accuracy of 0.995\n",
      "Epoch 1194, Overall loss = 0.0505 and accuracy of 0.993\n",
      "Epoch 1195, Overall loss = 0.049 and accuracy of 0.99\n",
      "Epoch 1196, Overall loss = 0.0472 and accuracy of 0.993\n",
      "Epoch 1197, Overall loss = 0.043 and accuracy of 0.994\n",
      "Epoch 1198, Overall loss = 0.0669 and accuracy of 0.993\n",
      "Epoch 1199, Overall loss = 0.0456 and accuracy of 0.995\n",
      "Epoch 1200, Overall loss = 0.0634 and accuracy of 0.988\n",
      "Iteration2400: with minibatch training loss = 0.0396 and accuracy of 0.99\n",
      "Epoch 1201, Overall loss = 0.0366 and accuracy of 0.996\n",
      "Epoch 1202, Overall loss = 0.0564 and accuracy of 0.991\n",
      "Epoch 1203, Overall loss = 0.0643 and accuracy of 0.991\n",
      "Epoch 1204, Overall loss = 0.054 and accuracy of 0.994\n",
      "Epoch 1205, Overall loss = 0.0708 and accuracy of 0.988\n",
      "Epoch 1206, Overall loss = 0.0583 and accuracy of 0.989\n",
      "Epoch 1207, Overall loss = 0.0535 and accuracy of 0.991\n",
      "Epoch 1208, Overall loss = 0.0515 and accuracy of 0.993\n",
      "Epoch 1209, Overall loss = 0.0532 and accuracy of 0.993\n",
      "Epoch 1210, Overall loss = 0.0521 and accuracy of 0.993\n",
      "Epoch 1211, Overall loss = 0.056 and accuracy of 0.994\n",
      "Epoch 1212, Overall loss = 0.0524 and accuracy of 0.989\n",
      "Epoch 1213, Overall loss = 0.048 and accuracy of 0.993\n",
      "Epoch 1214, Overall loss = 0.0448 and accuracy of 0.994\n",
      "Epoch 1215, Overall loss = 0.0451 and accuracy of 0.993\n",
      "Epoch 1216, Overall loss = 0.0311 and accuracy of 0.999\n",
      "Epoch 1217, Overall loss = 0.0471 and accuracy of 0.994\n",
      "Epoch 1218, Overall loss = 0.0899 and accuracy of 0.984\n",
      "Epoch 1219, Overall loss = 0.0653 and accuracy of 0.988\n",
      "Epoch 1220, Overall loss = 0.042 and accuracy of 0.995\n",
      "Epoch 1221, Overall loss = 0.0604 and accuracy of 0.991\n",
      "Epoch 1222, Overall loss = 0.0611 and accuracy of 0.989\n",
      "Epoch 1223, Overall loss = 0.0637 and accuracy of 0.988\n",
      "Epoch 1224, Overall loss = 0.0549 and accuracy of 0.993\n",
      "Epoch 1225, Overall loss = 0.0498 and accuracy of 0.994\n",
      "Epoch 1226, Overall loss = 0.053 and accuracy of 0.99\n",
      "Epoch 1227, Overall loss = 0.0489 and accuracy of 0.991\n",
      "Epoch 1228, Overall loss = 0.0369 and accuracy of 0.995\n",
      "Epoch 1229, Overall loss = 0.0596 and accuracy of 0.988\n",
      "Epoch 1230, Overall loss = 0.0436 and accuracy of 0.991\n",
      "Epoch 1231, Overall loss = 0.0354 and accuracy of 0.998\n",
      "Epoch 1232, Overall loss = 0.0551 and accuracy of 0.989\n",
      "Epoch 1233, Overall loss = 0.0757 and accuracy of 0.986\n",
      "Epoch 1234, Overall loss = 0.0434 and accuracy of 0.99\n",
      "Epoch 1235, Overall loss = 0.0419 and accuracy of 0.995\n",
      "Epoch 1236, Overall loss = 0.0524 and accuracy of 0.991\n",
      "Epoch 1237, Overall loss = 0.0552 and accuracy of 0.988\n",
      "Epoch 1238, Overall loss = 0.0448 and accuracy of 0.996\n",
      "Epoch 1239, Overall loss = 0.0543 and accuracy of 0.99\n",
      "Epoch 1240, Overall loss = 0.0613 and accuracy of 0.991\n",
      "Epoch 1241, Overall loss = 0.0524 and accuracy of 0.995\n",
      "Epoch 1242, Overall loss = 0.0467 and accuracy of 0.993\n",
      "Epoch 1243, Overall loss = 0.0432 and accuracy of 0.994\n",
      "Epoch 1244, Overall loss = 0.061 and accuracy of 0.984\n",
      "Epoch 1245, Overall loss = 0.0386 and accuracy of 0.996\n",
      "Epoch 1246, Overall loss = 0.0597 and accuracy of 0.988\n",
      "Epoch 1247, Overall loss = 0.0579 and accuracy of 0.99\n",
      "Epoch 1248, Overall loss = 0.0608 and accuracy of 0.989\n",
      "Epoch 1249, Overall loss = 0.058 and accuracy of 0.993\n",
      "Epoch 1250, Overall loss = 0.0551 and accuracy of 0.99\n",
      "Iteration2500: with minibatch training loss = 0.0467 and accuracy of 0.99\n",
      "Epoch 1251, Overall loss = 0.0502 and accuracy of 0.99\n",
      "Epoch 1252, Overall loss = 0.0438 and accuracy of 0.994\n",
      "Epoch 1253, Overall loss = 0.0417 and accuracy of 0.993\n",
      "Epoch 1254, Overall loss = 0.0529 and accuracy of 0.994\n",
      "Epoch 1255, Overall loss = 0.0542 and accuracy of 0.99\n",
      "Epoch 1256, Overall loss = 0.0535 and accuracy of 0.99\n",
      "Epoch 1257, Overall loss = 0.0559 and accuracy of 0.988\n",
      "Epoch 1258, Overall loss = 0.0692 and accuracy of 0.988\n",
      "Epoch 1259, Overall loss = 0.045 and accuracy of 0.994\n",
      "Epoch 1260, Overall loss = 0.0608 and accuracy of 0.993\n",
      "Epoch 1261, Overall loss = 0.0524 and accuracy of 0.99\n",
      "Epoch 1262, Overall loss = 0.044 and accuracy of 0.993\n",
      "Epoch 1263, Overall loss = 0.058 and accuracy of 0.988\n",
      "Epoch 1264, Overall loss = 0.0786 and accuracy of 0.986\n",
      "Epoch 1265, Overall loss = 0.0517 and accuracy of 0.994\n",
      "Epoch 1266, Overall loss = 0.0444 and accuracy of 0.995\n",
      "Epoch 1267, Overall loss = 0.0572 and accuracy of 0.99\n",
      "Epoch 1268, Overall loss = 0.0643 and accuracy of 0.989\n",
      "Epoch 1269, Overall loss = 0.0755 and accuracy of 0.984\n",
      "Epoch 1270, Overall loss = 0.0493 and accuracy of 0.991\n",
      "Epoch 1271, Overall loss = 0.0641 and accuracy of 0.991\n",
      "Epoch 1272, Overall loss = 0.0481 and accuracy of 0.994\n",
      "Epoch 1273, Overall loss = 0.0542 and accuracy of 0.99\n",
      "Epoch 1274, Overall loss = 0.0595 and accuracy of 0.99\n",
      "Epoch 1275, Overall loss = 0.0388 and accuracy of 0.994\n",
      "Epoch 1276, Overall loss = 0.05 and accuracy of 0.991\n",
      "Epoch 1277, Overall loss = 0.0684 and accuracy of 0.991\n",
      "Epoch 1278, Overall loss = 0.0408 and accuracy of 0.995\n",
      "Epoch 1279, Overall loss = 0.0665 and accuracy of 0.988\n",
      "Epoch 1280, Overall loss = 0.0501 and accuracy of 0.993\n",
      "Epoch 1281, Overall loss = 0.0617 and accuracy of 0.993\n",
      "Epoch 1282, Overall loss = 0.0625 and accuracy of 0.986\n",
      "Epoch 1283, Overall loss = 0.0484 and accuracy of 0.993\n",
      "Epoch 1284, Overall loss = 0.0467 and accuracy of 0.994\n",
      "Epoch 1285, Overall loss = 0.0453 and accuracy of 0.991\n",
      "Epoch 1286, Overall loss = 0.0471 and accuracy of 0.993\n",
      "Epoch 1287, Overall loss = 0.0705 and accuracy of 0.985\n",
      "Epoch 1288, Overall loss = 0.0639 and accuracy of 0.988\n",
      "Epoch 1289, Overall loss = 0.0496 and accuracy of 0.988\n",
      "Epoch 1290, Overall loss = 0.0617 and accuracy of 0.986\n",
      "Epoch 1291, Overall loss = 0.08 and accuracy of 0.988\n",
      "Epoch 1292, Overall loss = 0.0583 and accuracy of 0.989\n",
      "Epoch 1293, Overall loss = 0.059 and accuracy of 0.988\n",
      "Epoch 1294, Overall loss = 0.0579 and accuracy of 0.99\n",
      "Epoch 1295, Overall loss = 0.0652 and accuracy of 0.989\n",
      "Epoch 1296, Overall loss = 0.0527 and accuracy of 0.993\n",
      "Epoch 1297, Overall loss = 0.0418 and accuracy of 0.996\n",
      "Epoch 1298, Overall loss = 0.0574 and accuracy of 0.991\n",
      "Epoch 1299, Overall loss = 0.0513 and accuracy of 0.99\n",
      "Epoch 1300, Overall loss = 0.0715 and accuracy of 0.985\n",
      "Iteration2600: with minibatch training loss = 0.0535 and accuracy of 0.99\n",
      "Epoch 1301, Overall loss = 0.0527 and accuracy of 0.989\n",
      "Epoch 1302, Overall loss = 0.0772 and accuracy of 0.986\n",
      "Epoch 1303, Overall loss = 0.0464 and accuracy of 0.994\n",
      "Epoch 1304, Overall loss = 0.0489 and accuracy of 0.991\n",
      "Epoch 1305, Overall loss = 0.0641 and accuracy of 0.991\n",
      "Epoch 1306, Overall loss = 0.0516 and accuracy of 0.994\n",
      "Epoch 1307, Overall loss = 0.0578 and accuracy of 0.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1308, Overall loss = 0.0597 and accuracy of 0.989\n",
      "Epoch 1309, Overall loss = 0.0384 and accuracy of 0.999\n",
      "Epoch 1310, Overall loss = 0.0519 and accuracy of 0.994\n",
      "Epoch 1311, Overall loss = 0.0528 and accuracy of 0.995\n",
      "Epoch 1312, Overall loss = 0.0456 and accuracy of 0.995\n",
      "Epoch 1313, Overall loss = 0.0683 and accuracy of 0.99\n",
      "Epoch 1314, Overall loss = 0.0394 and accuracy of 0.999\n",
      "Epoch 1315, Overall loss = 0.0508 and accuracy of 0.99\n",
      "Epoch 1316, Overall loss = 0.0657 and accuracy of 0.988\n",
      "Epoch 1317, Overall loss = 0.0422 and accuracy of 0.994\n",
      "Epoch 1318, Overall loss = 0.0642 and accuracy of 0.991\n",
      "Epoch 1319, Overall loss = 0.0455 and accuracy of 0.994\n",
      "Epoch 1320, Overall loss = 0.0598 and accuracy of 0.989\n",
      "Epoch 1321, Overall loss = 0.0525 and accuracy of 0.995\n",
      "Epoch 1322, Overall loss = 0.062 and accuracy of 0.99\n",
      "Epoch 1323, Overall loss = 0.0601 and accuracy of 0.988\n",
      "Epoch 1324, Overall loss = 0.0573 and accuracy of 0.99\n",
      "Epoch 1325, Overall loss = 0.0394 and accuracy of 0.995\n",
      "Epoch 1326, Overall loss = 0.0506 and accuracy of 0.989\n",
      "Epoch 1327, Overall loss = 0.0715 and accuracy of 0.986\n",
      "Epoch 1328, Overall loss = 0.0674 and accuracy of 0.991\n",
      "Epoch 1329, Overall loss = 0.0695 and accuracy of 0.981\n",
      "Epoch 1330, Overall loss = 0.0541 and accuracy of 0.989\n",
      "Epoch 1331, Overall loss = 0.0477 and accuracy of 0.993\n",
      "Epoch 1332, Overall loss = 0.0405 and accuracy of 0.996\n",
      "Epoch 1333, Overall loss = 0.0775 and accuracy of 0.979\n",
      "Epoch 1334, Overall loss = 0.0512 and accuracy of 0.991\n",
      "Epoch 1335, Overall loss = 0.0603 and accuracy of 0.991\n",
      "Epoch 1336, Overall loss = 0.0768 and accuracy of 0.985\n",
      "Epoch 1337, Overall loss = 0.0489 and accuracy of 0.993\n",
      "Epoch 1338, Overall loss = 0.0591 and accuracy of 0.986\n",
      "Epoch 1339, Overall loss = 0.053 and accuracy of 0.991\n",
      "Epoch 1340, Overall loss = 0.0396 and accuracy of 0.995\n",
      "Epoch 1341, Overall loss = 0.0741 and accuracy of 0.989\n",
      "Epoch 1342, Overall loss = 0.067 and accuracy of 0.99\n",
      "Epoch 1343, Overall loss = 0.0678 and accuracy of 0.991\n",
      "Epoch 1344, Overall loss = 0.0475 and accuracy of 0.994\n",
      "Epoch 1345, Overall loss = 0.041 and accuracy of 0.996\n",
      "Epoch 1346, Overall loss = 0.0587 and accuracy of 0.991\n",
      "Epoch 1347, Overall loss = 0.0476 and accuracy of 0.993\n",
      "Epoch 1348, Overall loss = 0.053 and accuracy of 0.991\n",
      "Epoch 1349, Overall loss = 0.095 and accuracy of 0.984\n",
      "Epoch 1350, Overall loss = 0.0536 and accuracy of 0.991\n",
      "Iteration2700: with minibatch training loss = 0.0638 and accuracy of 0.99\n",
      "Epoch 1351, Overall loss = 0.0536 and accuracy of 0.993\n",
      "Epoch 1352, Overall loss = 0.0785 and accuracy of 0.981\n",
      "Epoch 1353, Overall loss = 0.0466 and accuracy of 0.991\n",
      "Epoch 1354, Overall loss = 0.0516 and accuracy of 0.994\n",
      "Epoch 1355, Overall loss = 0.0555 and accuracy of 0.995\n",
      "Epoch 1356, Overall loss = 0.0934 and accuracy of 0.985\n",
      "Epoch 1357, Overall loss = 0.0462 and accuracy of 0.994\n",
      "Epoch 1358, Overall loss = 0.0466 and accuracy of 0.995\n",
      "Epoch 1359, Overall loss = 0.0556 and accuracy of 0.989\n",
      "Epoch 1360, Overall loss = 0.0655 and accuracy of 0.986\n",
      "Epoch 1361, Overall loss = 0.0527 and accuracy of 0.989\n",
      "Epoch 1362, Overall loss = 0.0479 and accuracy of 0.993\n",
      "Epoch 1363, Overall loss = 0.0546 and accuracy of 0.991\n",
      "Epoch 1364, Overall loss = 0.0529 and accuracy of 0.99\n",
      "Epoch 1365, Overall loss = 0.0516 and accuracy of 0.988\n",
      "Epoch 1366, Overall loss = 0.0347 and accuracy of 0.995\n",
      "Epoch 1367, Overall loss = 0.0471 and accuracy of 0.989\n",
      "Epoch 1368, Overall loss = 0.0446 and accuracy of 0.993\n",
      "Epoch 1369, Overall loss = 0.0535 and accuracy of 0.993\n",
      "Epoch 1370, Overall loss = 0.0425 and accuracy of 0.994\n",
      "Epoch 1371, Overall loss = 0.0361 and accuracy of 0.994\n",
      "Epoch 1372, Overall loss = 0.0595 and accuracy of 0.993\n",
      "Epoch 1373, Overall loss = 0.0803 and accuracy of 0.986\n",
      "Epoch 1374, Overall loss = 0.0494 and accuracy of 0.991\n",
      "Epoch 1375, Overall loss = 0.0583 and accuracy of 0.989\n",
      "Epoch 1376, Overall loss = 0.0676 and accuracy of 0.986\n",
      "Epoch 1377, Overall loss = 0.0759 and accuracy of 0.983\n",
      "Epoch 1378, Overall loss = 0.0455 and accuracy of 0.99\n",
      "Epoch 1379, Overall loss = 0.0587 and accuracy of 0.993\n",
      "Epoch 1380, Overall loss = 0.0482 and accuracy of 0.993\n",
      "Epoch 1381, Overall loss = 0.0658 and accuracy of 0.99\n",
      "Epoch 1382, Overall loss = 0.0572 and accuracy of 0.991\n",
      "Epoch 1383, Overall loss = 0.0776 and accuracy of 0.989\n",
      "Epoch 1384, Overall loss = 0.053 and accuracy of 0.99\n",
      "Epoch 1385, Overall loss = 0.0506 and accuracy of 0.994\n",
      "Epoch 1386, Overall loss = 0.0547 and accuracy of 0.991\n",
      "Epoch 1387, Overall loss = 0.0458 and accuracy of 0.99\n",
      "Epoch 1388, Overall loss = 0.0432 and accuracy of 0.994\n",
      "Epoch 1389, Overall loss = 0.0767 and accuracy of 0.989\n",
      "Epoch 1390, Overall loss = 0.0518 and accuracy of 0.991\n",
      "Epoch 1391, Overall loss = 0.051 and accuracy of 0.991\n",
      "Epoch 1392, Overall loss = 0.0614 and accuracy of 0.99\n",
      "Epoch 1393, Overall loss = 0.0587 and accuracy of 0.989\n",
      "Epoch 1394, Overall loss = 0.0786 and accuracy of 0.989\n",
      "Epoch 1395, Overall loss = 0.0508 and accuracy of 0.994\n",
      "Epoch 1396, Overall loss = 0.0557 and accuracy of 0.993\n",
      "Epoch 1397, Overall loss = 0.0501 and accuracy of 0.991\n",
      "Epoch 1398, Overall loss = 0.0428 and accuracy of 0.99\n",
      "Epoch 1399, Overall loss = 0.0514 and accuracy of 0.994\n",
      "Epoch 1400, Overall loss = 0.0441 and accuracy of 0.991\n",
      "Iteration2800: with minibatch training loss = 0.0404 and accuracy of 1\n",
      "Epoch 1401, Overall loss = 0.0515 and accuracy of 0.995\n",
      "Epoch 1402, Overall loss = 0.0449 and accuracy of 0.991\n",
      "Epoch 1403, Overall loss = 0.048 and accuracy of 0.993\n",
      "Epoch 1404, Overall loss = 0.0517 and accuracy of 0.991\n",
      "Epoch 1405, Overall loss = 0.0396 and accuracy of 0.996\n",
      "Epoch 1406, Overall loss = 0.0563 and accuracy of 0.991\n",
      "Epoch 1407, Overall loss = 0.0401 and accuracy of 0.993\n",
      "Epoch 1408, Overall loss = 0.0481 and accuracy of 0.994\n",
      "Epoch 1409, Overall loss = 0.0608 and accuracy of 0.993\n",
      "Epoch 1410, Overall loss = 0.0499 and accuracy of 0.994\n",
      "Epoch 1411, Overall loss = 0.0434 and accuracy of 0.996\n",
      "Epoch 1412, Overall loss = 0.0525 and accuracy of 0.993\n",
      "Epoch 1413, Overall loss = 0.0395 and accuracy of 0.994\n",
      "Epoch 1414, Overall loss = 0.0404 and accuracy of 0.994\n",
      "Epoch 1415, Overall loss = 0.043 and accuracy of 0.993\n",
      "Epoch 1416, Overall loss = 0.0526 and accuracy of 0.99\n",
      "Epoch 1417, Overall loss = 0.0422 and accuracy of 0.996\n",
      "Epoch 1418, Overall loss = 0.0535 and accuracy of 0.993\n",
      "Epoch 1419, Overall loss = 0.037 and accuracy of 0.995\n",
      "Epoch 1420, Overall loss = 0.0515 and accuracy of 0.991\n",
      "Epoch 1421, Overall loss = 0.0564 and accuracy of 0.994\n",
      "Epoch 1422, Overall loss = 0.0522 and accuracy of 0.994\n",
      "Epoch 1423, Overall loss = 0.054 and accuracy of 0.991\n",
      "Epoch 1424, Overall loss = 0.044 and accuracy of 0.993\n",
      "Epoch 1425, Overall loss = 0.0542 and accuracy of 0.99\n",
      "Epoch 1426, Overall loss = 0.0328 and accuracy of 0.996\n",
      "Epoch 1427, Overall loss = 0.0595 and accuracy of 0.99\n",
      "Epoch 1428, Overall loss = 0.0461 and accuracy of 0.99\n",
      "Epoch 1429, Overall loss = 0.0476 and accuracy of 0.991\n",
      "Epoch 1430, Overall loss = 0.0408 and accuracy of 0.993\n",
      "Epoch 1431, Overall loss = 0.043 and accuracy of 0.995\n",
      "Epoch 1432, Overall loss = 0.075 and accuracy of 0.986\n",
      "Epoch 1433, Overall loss = 0.042 and accuracy of 0.994\n",
      "Epoch 1434, Overall loss = 0.0501 and accuracy of 0.988\n",
      "Epoch 1435, Overall loss = 0.0454 and accuracy of 0.993\n",
      "Epoch 1436, Overall loss = 0.0513 and accuracy of 0.994\n",
      "Epoch 1437, Overall loss = 0.0588 and accuracy of 0.99\n",
      "Epoch 1438, Overall loss = 0.0416 and accuracy of 0.993\n",
      "Epoch 1439, Overall loss = 0.0516 and accuracy of 0.99\n",
      "Epoch 1440, Overall loss = 0.0372 and accuracy of 0.994\n",
      "Epoch 1441, Overall loss = 0.0567 and accuracy of 0.989\n",
      "Epoch 1442, Overall loss = 0.0634 and accuracy of 0.985\n",
      "Epoch 1443, Overall loss = 0.0574 and accuracy of 0.99\n",
      "Epoch 1444, Overall loss = 0.0395 and accuracy of 0.995\n",
      "Epoch 1445, Overall loss = 0.0604 and accuracy of 0.991\n",
      "Epoch 1446, Overall loss = 0.0628 and accuracy of 0.99\n",
      "Epoch 1447, Overall loss = 0.0749 and accuracy of 0.989\n",
      "Epoch 1448, Overall loss = 0.0566 and accuracy of 0.99\n",
      "Epoch 1449, Overall loss = 0.0741 and accuracy of 0.985\n",
      "Epoch 1450, Overall loss = 0.0638 and accuracy of 0.984\n",
      "Iteration2900: with minibatch training loss = 0.0421 and accuracy of 0.99\n",
      "Epoch 1451, Overall loss = 0.0408 and accuracy of 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1452, Overall loss = 0.0525 and accuracy of 0.989\n",
      "Epoch 1453, Overall loss = 0.0565 and accuracy of 0.988\n",
      "Epoch 1454, Overall loss = 0.0642 and accuracy of 0.986\n",
      "Epoch 1455, Overall loss = 0.0458 and accuracy of 0.993\n",
      "Epoch 1456, Overall loss = 0.0659 and accuracy of 0.99\n",
      "Epoch 1457, Overall loss = 0.0664 and accuracy of 0.985\n",
      "Epoch 1458, Overall loss = 0.0514 and accuracy of 0.994\n",
      "Epoch 1459, Overall loss = 0.0959 and accuracy of 0.984\n",
      "Epoch 1460, Overall loss = 0.076 and accuracy of 0.984\n",
      "Epoch 1461, Overall loss = 0.0907 and accuracy of 0.98\n",
      "Epoch 1462, Overall loss = 0.058 and accuracy of 0.99\n",
      "Epoch 1463, Overall loss = 0.0838 and accuracy of 0.983\n",
      "Epoch 1464, Overall loss = 0.0503 and accuracy of 0.986\n",
      "Epoch 1465, Overall loss = 0.0578 and accuracy of 0.986\n",
      "Epoch 1466, Overall loss = 0.0935 and accuracy of 0.983\n",
      "Epoch 1467, Overall loss = 0.0394 and accuracy of 0.995\n",
      "Epoch 1468, Overall loss = 0.0482 and accuracy of 0.991\n",
      "Epoch 1469, Overall loss = 0.0693 and accuracy of 0.991\n",
      "Epoch 1470, Overall loss = 0.0772 and accuracy of 0.988\n",
      "Epoch 1471, Overall loss = 0.0582 and accuracy of 0.99\n",
      "Epoch 1472, Overall loss = 0.0555 and accuracy of 0.991\n",
      "Epoch 1473, Overall loss = 0.0551 and accuracy of 0.986\n",
      "Epoch 1474, Overall loss = 0.0439 and accuracy of 0.995\n",
      "Epoch 1475, Overall loss = 0.0493 and accuracy of 0.989\n",
      "Epoch 1476, Overall loss = 0.0593 and accuracy of 0.991\n",
      "Epoch 1477, Overall loss = 0.0617 and accuracy of 0.993\n",
      "Epoch 1478, Overall loss = 0.0572 and accuracy of 0.99\n",
      "Epoch 1479, Overall loss = 0.054 and accuracy of 0.993\n",
      "Epoch 1480, Overall loss = 0.067 and accuracy of 0.984\n",
      "Epoch 1481, Overall loss = 0.0361 and accuracy of 0.998\n",
      "Epoch 1482, Overall loss = 0.0554 and accuracy of 0.993\n",
      "Epoch 1483, Overall loss = 0.0485 and accuracy of 0.991\n",
      "Epoch 1484, Overall loss = 0.0403 and accuracy of 0.995\n",
      "Epoch 1485, Overall loss = 0.0469 and accuracy of 0.996\n",
      "Epoch 1486, Overall loss = 0.0602 and accuracy of 0.989\n",
      "Epoch 1487, Overall loss = 0.0602 and accuracy of 0.988\n",
      "Epoch 1488, Overall loss = 0.0488 and accuracy of 0.994\n",
      "Epoch 1489, Overall loss = 0.0484 and accuracy of 0.991\n",
      "Epoch 1490, Overall loss = 0.0801 and accuracy of 0.986\n",
      "Epoch 1491, Overall loss = 0.0429 and accuracy of 0.991\n",
      "Epoch 1492, Overall loss = 0.0611 and accuracy of 0.989\n",
      "Epoch 1493, Overall loss = 0.0405 and accuracy of 0.996\n",
      "Epoch 1494, Overall loss = 0.064 and accuracy of 0.99\n",
      "Epoch 1495, Overall loss = 0.0646 and accuracy of 0.986\n",
      "Epoch 1496, Overall loss = 0.0422 and accuracy of 0.993\n",
      "Epoch 1497, Overall loss = 0.0555 and accuracy of 0.985\n",
      "Epoch 1498, Overall loss = 0.0487 and accuracy of 0.99\n",
      "Epoch 1499, Overall loss = 0.062 and accuracy of 0.986\n",
      "Epoch 1500, Overall loss = 0.0543 and accuracy of 0.99\n",
      "eval\n",
      "Epoch 1, Overall loss = 1.7 and accuracy of 0.73\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"Pretrain layer_1:\")\n",
    "    run_autoencoder(sess, layer_1_para['loss'], b_train_data, layer_1_para['y_pred'],\n",
    "                    1, 1000, 512, 50, \n",
    "                    layer_1_para['optimizer'], False)\n",
    "    print(\"Pretrain layer_2:\")\n",
    "    run_autoencoder(sess, layer_2_para['loss'], b_train_data, layer_2_para['y_pred'],\n",
    "                   1, 350, 512, 50,\n",
    "                   layer_2_para['optimizer'], False)\n",
    "    print(\"Pretrain layer_3:\")\n",
    "    run_autoencoder(sess, layer_3_para['loss'], b_train_data, layer_3_para['y_pred'],\n",
    "                    1, 250, 512, 50,\n",
    "                    layer_3_para['optimizer'], False)\n",
    "    print(\"train\")\n",
    "    dcf.run_model(sess, dcf.out, dcf.loss, b_train_data, b_train_labels.eval(), 0.55,\n",
    "                 1500, 512, 100,\n",
    "                 dcf.train_step, False)\n",
    "    print(\"eval\")\n",
    "    dcf.run_model(sess, dcf.out, dcf.loss, b_eval_data, b_eval_labels.eval(), 1, 1, 512)\n",
    "    \n",
    "    \n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
